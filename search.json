[{"title":"Dormitry","url":"/2021/01/24/Dormitry/","content":"来看看我的大学寝室吧~\n\n都是漂亮的小姐姐\n林晨曦（班里唯二女孩纸 相依为命\n叶涵    （yea~\n杨艺茜（又名唐怀瑟\n郭欣羽（文艺少女\n\n\n\n","categories":["HDU's Life"],"tags":["Daily"]},{"title":"A scene to remember","url":"/2021/08/03/Imitation/","content":"Good afternoon, ladies and gentlemen. Today I would like to begin with a story.\nThere was once a physical therapist who traveled all the way from America to Africa to do a census about mountain gorillas. These gorillas are a main attraction to tourists from all over the world; this put them severely under threat of poaching and being put into the zoo. She went there out of curiosity, but what she saw strengthened her determination to devote her whole life to fighting for those beautiful creatures. She witnessed a scene, a scene taking us to a place we never imaged we’ve ever been, where in the very depth of the African rainforest, surrounded by trees, flowers and butterflies, the mother gorillas cuddled their babies. Yes, that’s a memorable scene in one of my favorite movies, called Gorillas in the Mist, based on a true story of Mrs. Dian Fossey, who spent most of her lifetime in Rwanda to protect the ecoenvironment there until the very end of her life. To me, the movie not only presents an unforgettable scene but also acts as a timeless reminder that we should not develop the tourist industry at the cost of our ecoenvironment.\nToday, we live in a world of prosperity but still threatened by so many new problems. On the one hand, tourism, as one of the most promising industries in the 21st century, provides people with the great opportunity to see everything there is to see and to go any place there is to go. It has become a lifestyle for some people, and has turned out to be the driving force in GDP growth. It has the magic to turn a backward town into a wonderland of prosperity. But on the other hand, many problems can occur—-natural scenes aren’t natural anymore. Deforestation to heat lodges is devastating Nepal. \n","categories":["HDU's Learning"],"tags":["English speech"]},{"title":"Life shines on life","url":"/2021/08/02/Life-shines-on-life/","content":"“Yeah we all shine on, like the moon, and the stars, and the sun.”   ——John Lennon\n\n\n\nself-introHello, sir or madam. I’m Qi Yingying, a freshman learning computer science and technology in Hangzhou Dianzi University. In school, I’m a down-to-earth student. I believe in the words that “no pains, no gains”. Speaking of my hobbies, I’m a music buff and also love sporting. Running along Qianjiang River, immersing my ears into sweet songs and filling my eyes with the marvelous light of sun shine really keep me spellbound. \nLet’s move into the topic speech.\nTopic speechOver 85 years ago, The Red Army fears not the trials of the Long March, holding light ten thousand crags and torrents. The Five Ridges wind like gentle ripples, and the majestic Wumeng roll by. Oprah Winfrey said, “let your light shine. Shine within you so that it can shine on someone else.” yes, they still shines on our lives with their persistence and bravery. \nIn 2020, during the pandemic, retrogrades put on gloves and protective suits, devoted themselves into the fight against the virus. Their selflessness and love warmed our hearts in that cold winter.\nYeah we all shall shine on and we all can shine on, like the moon, and the stars, and the sun. Shining on life isn’t a tough task. Just by helping people in need and being grateful for the people who once helped us. Smile to a passer-by, pick up a rubbish on the road, give a hug to a crying man,  and say thank you to people who once support us. If only we are willing, we can shine our lives on lives.\nWe can shine in many ways. Nhat Hanh said, “Awareness is like the sun. When it shines on things, they are transformed.” Michael Jackson appeals people to love, heal and educate children. Let’s all do our duties on shining on lives.\n\n（写这些不想写的东西 已经要写吐了……\n果然 对于喜欢的东西 过犹不及……\n当初一腔热血，现在头都要没了……\n冲！！\n","categories":["HDU's Learning"],"tags":["English speech"]},{"title":"OpenCV (创建新项目)","url":"/2021/07/26/OPENCV1-0-0/","content":"开始学习啦~~\n\nStep 1Go to https://github.com/opencv/opencv and download the Latest Release.\nStep 2Add bin folder to the Environment Variables path.（编辑系统环境变量）\nD:\\opencv\\build\\x64\\vc15\\bin\nStep 3Create a New Visual Studio project C++ console.\nSet the platform target to x64.\nStep 4Add Directories by going to Project-Properties-Configuration Properties. （项目 - 属性 -  配置属性）\nVC++目录 - 包含目录 &amp;&amp; 库目录\nAdd build directories D:\\opencv\\build\\include \nAdd Library directories D:\\opencv\\build\\x64\\vc15\\lib \n链接器 - 输入\nAdd linker input opencv_world450d.lib \n不同版本不一样，数字后面有d的与debug有关，没有d的与release有关。\n具体操作可参照 https://www.bilibili.com/video/BV11A411T7rL?t=2\n视频相关资源下载 https://www.murtazahassan.com/courses/opencv-cpp-course/\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"OpenCV (背景单一小球视频跟踪)","url":"/2021/07/29/OPENCV1-2/","content":"小作业—视频跟踪\n\n  我们录制了一段视频，视频内容如下：\n一个红色（可能是橙色……）的小球，从地上滚过去\n视频特征：1. 背景单一 2. 要捕捉的对象与背景具有明显的颜色差别\n学长的初步代码终于能跑起来了！！！\n#include &quot;opencv2/opencv.hpp&quot;#include &quot;opencv2/video/background_segm.hpp&quot;#include&lt;iostream&gt;using namespace std;using namespace cv;void main() &#123;\t\tVideoCapture video(&quot;D:/Summer Holiday Practice/opencv learning/Resources/tast.mp4&quot;);\t\tint frameNum = 1;\t\tMat frame, mask, thresholdImage, output;\t\tif (!video.isOpened())\t\t\tcout &lt;&lt; &quot;fail to open!&quot; &lt;&lt; endl;\t\t//cout&lt;&lt;video.isOpened();\t\tdouble totalFrameNumber = video.get(CAP_PROP_FRAME_COUNT);\t\tvideo &gt;&gt; frame;\t\tPtr&lt;BackgroundSubtractorMOG2&gt; bgsubtractor = createBackgroundSubtractorMOG2();\t\tbgsubtractor-&gt;setVarThreshold(20);\t\twhile (true) &#123;\t\t\tif (totalFrameNumber == frameNum)\t\t\t\tbreak;\t\t\tvideo &gt;&gt; frame;\t\t\t++frameNum;\t\t\t//bgSubtractor(frame, mask, 0.001);\t\t\tbgsubtractor-&gt;apply(frame, mask, 0.01);\t\t\timshow(&quot;mask&quot;, mask);\t\t\twaitKey(10);\t\t&#125;&#125;\n学长的最终代码\n学长不愧是学长，太巨了！！！！\n#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;#include&lt;opencv2/core.hpp&gt;\tusing namespace std;using namespace cv;/// &lt;summary&gt;/// Project 1/// 使用HSV空间检测颜色、找到轮廓所在位置、取轮廓的位置然后创建一个圆/// &lt;/summary&gt;Mat img;vector&lt;vector&lt;int&gt;&gt; newPoints;vector&lt;vector&lt;int&gt;&gt; myColors&#123; &#123;0,87,54,15,205,245&#125;,//橙色（hmin smin vmin hmax smax vmax）\t\t\t\t\t\t\t\t&#123;0,0,0,0,0,0&#125; &#125;;//绿色（hmin smin vmin hmax smax vmax）vector&lt;Scalar&gt; myColorValues&#123; &#123;255,0,255&#125;,//蓝色\t\t\t\t\t\t\t\t&#123;0,255,0&#125; &#125;;//绿色//! 获取轮廓Point getContours(Mat imgDil) &#123;//imgDil是传入的扩张边缘的图像用来查找轮廓，img是要在其上绘制轮廓的图像\tvector&lt;vector&lt;Point&gt;&gt; contours;//轮廓检测到的轮廓。每个轮廓线存储为一个点的向量\tvector&lt;Vec4i&gt; hierarchy;//包含关于映像拓扑的信息  typedef Vec&lt;int, 4&gt; Vec4i;具有4个整数值\t//在二值图像中查找轮廓。该函数利用该算法从二值图像中提取轮廓\tfindContours(imgDil, contours, hierarchy, RETR_LIST, CHAIN_APPROX_SIMPLE);\t//drawContours(img, contours, -1, Scalar(255, 0, 255), 2);//img：要绘制轮廓在什么图片上，contours：要绘制的轮廓，-1定义要绘制的轮廓号（-1表示所有轮廓），Saclar表示轮廓颜色，2表示厚度\t\tvector&lt;vector&lt;Point&gt;&gt; conPoly(contours.size());//conploy的数量应小于contours\tvector&lt;Rect&gt; boundRect(contours.size());\tPoint myPoint(0, 0);\t//过滤器：通过轮廓面积来过滤噪声\tfor (int i = 0; i &lt; contours.size(); i++) &#123;//遍历检测到的轮廓\t\tint area = contourArea(contours[i]);\t\t\t\t//cout &lt;&lt; area &lt;&lt; endl;\t\tstring objectType;\t\tif (area &gt; 1000) &#123;//轮廓面积＞1000才绘制\t\t\t//计算轮廓周长或凹坑长度。该函数计算了曲线长度和封闭的周长。\t\t\tfloat peri = arcLength(contours[i], true);//计算封闭轮廓周长\t\t\tapproxPolyDP(contours[i], conPoly[i], 0.02 * peri, true);//以指定的精度近似多边形曲线。第二个参数conPloy[i]存储近似的结果，是输出。\t\t\tboundRect[i] = boundingRect(conPoly[i]);//计算边界矩形\t\t\tmyPoint.x = boundRect[i].x;\t\t\tmyPoint.y = boundRect[i].y + boundRect[i].height / 2;\t\t\tif (conPoly[i].size() &gt; 4)\t\t\t\tputText(img, &quot;Small Ball&quot;, Point(boundRect[i].x, boundRect[i].y - 10), FONT_HERSHEY_PLAIN ,3 , Scalar(0, 255, 0), 6);\t\t\t/*绘制边界矩形*/\t\t\trectangle(img, boundRect[i].tl(), boundRect[i].br(), Scalar(0, 255, 0), 5);//tl()：topleft矩形左上角坐标 br()：bottom right矩形右下角坐标\t\t\tdrawContours(img, conPoly, i, Scalar(255, 0, 0), 2);\t\t&#125;\t&#125;\treturn myPoint;&#125;vector&lt;vector&lt;int&gt;&gt; findColor(Mat img) &#123;\tMat imgHSV;\tcvtColor(img, imgHSV, COLOR_BGR2HSV);//转换图像到HSV空间，在其中查找颜色更加容易\tfor (int i = 0; i &lt; myColors.size(); i++)\t&#123;\t\tScalar lower(myColors[i][0], myColors[i][1], myColors[i][2]);\t\tScalar upper(myColors[i][3], myColors[i][4], myColors[i][5]);\t\tMat mask;\t\tinRange(imgHSV, lower, upper, mask);//定义颜色下限和上限，因为由于照明和不同的阴影，颜色的值将不完全相同，会是一个值的范围\t\t//imshow(to_string(i), mask);\t\tPoint myPoint=getContours(mask);\t\tif (myPoint.x != 0 &amp;&amp; myPoint.y != 0) &#123;//没检测到东西的时候就不加入新点\t\t\tnewPoints.push_back(&#123; myPoint.x,myPoint.y,i &#125;);//i为颜色索引\t\t&#125;\t&#125;\treturn newPoints;\t&#125;void drawOnCanvas(vector&lt;vector&lt;int&gt;&gt; newPoints, vector&lt;Scalar&gt; myColorValues) &#123;\tfor (int i = 1; i &lt; newPoints.size(); i++) &#123;\t\tline(img, Point(newPoints[i - 1][0], newPoints[i - 1][1]), Point(newPoints[i][0], newPoints[i][1]), Scalar(0, 255, 255), 10);\t&#125;&#125;void main() &#123;\tVideoCapture cap(&quot;Resources/task.mp4&quot;);//相机id=0\tchar c;\tbool stop = false;\tnamedWindow(&quot;Image&quot;, WINDOW_FREERATIO);\twhile (c = waitKey(1))\t&#123;\t\tif (c == 27)\t\t\tbreak;\t\tif (c == &#x27;p&#x27;)\t\t&#123;\t\t\tstop = !stop;\t\t&#125;\t\tif (!stop)\t\t&#123;\t\t\tcap &gt;&gt; img;\t\t\tnewPoints = findColor(img);\t\t\tdrawOnCanvas(newPoints, myColorValues);\t\t\timshow(&quot;Image&quot;, img);\t\t&#125;\t&#125;&#125;\n我首先更改了视频读取的路径\nD:/Summer Holiday Practice/opencv learning/Resources/task2.mp4\n编译运行后，视频闪退了！？？！\n随后，调整了调试属性。平台从 x64活动 调整为 x64\n在我的电脑上最终代码如下\n#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;#include&lt;opencv2/core.hpp&gt;\tusing namespace std;using namespace cv;/// &lt;summary&gt;/// Project 1/// 使用HSV空间检测颜色、找到轮廓所在位置、取轮廓的位置然后创建一个圆/// &lt;/summary&gt;Mat img;vector&lt;vector&lt;int&gt;&gt; newPoints;vector&lt;vector&lt;int&gt;&gt; myColors&#123; &#123;0,87,54,15,205,245&#125;,//橙色（hmin smin vmin hmax smax vmax）\t\t\t\t\t\t\t\t&#123;0,0,0,0,0,0&#125; &#125;;//绿色（hmin smin vmin hmax smax vmax）vector&lt;Scalar&gt; myColorValues&#123; &#123;255,0,255&#125;,//蓝色\t\t\t\t\t\t\t\t&#123;0,255,0&#125; &#125;;//绿色//! 获取轮廓Point getContours(Mat imgDil) &#123;//imgDil是传入的扩张边缘的图像用来查找轮廓，img是要在其上绘制轮廓的图像\tvector&lt;vector&lt;Point&gt;&gt; contours;//轮廓检测到的轮廓。每个轮廓线存储为一个点的向量\tvector&lt;Vec4i&gt; hierarchy;//包含关于映像拓扑的信息  typedef Vec&lt;int, 4&gt; Vec4i;具有4个整数值\t//在二值图像中查找轮廓。该函数利用该算法从二值图像中提取轮廓\tfindContours(imgDil, contours, hierarchy, RETR_LIST, CHAIN_APPROX_SIMPLE);\t//drawContours(img, contours, -1, Scalar(255, 0, 255), 2);//img：要绘制轮廓在什么图片上，contours：要绘制的轮廓，-1定义要绘制的轮廓号（-1表示所有轮廓），Saclar表示轮廓颜色，2表示厚度\tvector&lt;vector&lt;Point&gt;&gt; conPoly(contours.size());//conploy的数量应小于contours\tvector&lt;Rect&gt; boundRect(contours.size());\tPoint myPoint(0, 0);\t//过滤器：通过轮廓面积来过滤噪声\tfor (int i = 0; i &lt; contours.size(); i++) &#123;//遍历检测到的轮廓\t\tdouble area = contourArea(contours[i]);\t\t//cout &lt;&lt; area &lt;&lt; endl;\t\tstring objectType;\t\tif (area &gt; 1000) &#123;//轮廓面积＞1000才绘制\t\t\t//计算轮廓周长或凹坑长度。该函数计算了曲线长度和封闭的周长。\t\t\tdouble peri = arcLength(contours[i], true);//计算封闭轮廓周长\t\t\tapproxPolyDP(contours[i], conPoly[i], 0.02 * peri, true);//以指定的精度近似多边形曲线。第二个参数conPloy[i]存储近似的结果，是输出。\t\t\tboundRect[i] = boundingRect(conPoly[i]);//计算边界矩形\t\t\tmyPoint.x = boundRect[i].x;\t\t\tmyPoint.y = boundRect[i].y + boundRect[i].height / 2;\t\t\tif (conPoly[i].size() &gt; 4)\t\t\t\tputText(img, &quot;Small Ball&quot;, Point(boundRect[i].x, boundRect[i].y - 10), FONT_HERSHEY_PLAIN, 3, Scalar(0, 255, 0), 6);\t\t\t/*绘制边界矩形*/\t\t\trectangle(img, boundRect[i].tl(), boundRect[i].br(), Scalar(0, 255, 0), 5);//tl()：topleft矩形左上角坐标 br()：bottom right矩形右下角坐标\t\t\tdrawContours(img, conPoly, i, Scalar(255, 0, 0), 2);\t\t&#125;\t&#125;\treturn myPoint;&#125;vector&lt;vector&lt;int&gt;&gt; findColor(Mat img) &#123;\tMat imgHSV;\tcvtColor(img, imgHSV, COLOR_BGR2HSV);//转换图像到HSV空间，在其中查找颜色更加容易\tfor (int i = 0; i &lt; myColors.size(); i++)\t&#123;\t\tScalar lower(myColors[i][0], myColors[i][1], myColors[i][2]);\t\tScalar upper(myColors[i][3], myColors[i][4], myColors[i][5]);\t\tMat mask;\t\tinRange(imgHSV, lower, upper, mask);//定义颜色下限和上限，因为由于照明和不同的阴影，颜色的值将不完全相同，会是一个值的范围\t\t//imshow(to_string(i), mask);\t\tPoint myPoint = getContours(mask);\t\tif (myPoint.x != 0 &amp;&amp; myPoint.y != 0) &#123;//没检测到东西的时候就不加入新点\t\t\tnewPoints.push_back(&#123; myPoint.x,myPoint.y,i &#125;);//i为颜色索引\t\t&#125;\t&#125;\treturn newPoints;&#125;void drawOnCanvas(vector&lt;vector&lt;int&gt;&gt; newPoints, vector&lt;Scalar&gt; myColorValues) &#123;\tfor (int i = 1; i &lt; newPoints.size(); i++) &#123;\t\tline(img, Point(newPoints[i - 1][0], newPoints[i - 1][1]), Point(newPoints[i][0], newPoints[i][1]), Scalar(0, 255, 255), 10);\t&#125;&#125;int main() &#123;\tVideoCapture cap(&quot;D:/Summer Holiday Practice/opencv learning/Resources/tast.mp4&quot;);//相机id=0\tif (!cap.isOpened()) &#123;\t\tcout &lt;&lt; &quot;fail to open!&quot; &lt;&lt; endl;\t\treturn -1;\t&#125;\tchar c;\tbool stop = false;\tnamedWindow(&quot;Image&quot;, WINDOW_FREERATIO);\twhile (c = waitKey(1))\t&#123;\t\tif (c == 27)\t\t\tbreak;\t\tif (c == &#x27;p&#x27;)\t\t&#123;\t\t\tstop = !stop;\t\t&#125;\t\tif (!stop)\t\t&#123;\t\t\tcap &gt;&gt; img;\t\t\tnewPoints = findColor(img);\t\t\tdrawOnCanvas(newPoints, myColorValues);\t\t\timshow(&quot;Image&quot;, img);\t\t&#125;\t&#125;\treturn 0;&#125;\n\n\n代码跑起来了，就来认真学习一下学长的 “高级” 代码呐~\n解剖代码ing~\n全局变量Mat img;vector&lt;vector&lt;int&gt;&gt; newPoints;//HSV颜色空间vector&lt;vector&lt;int&gt;&gt; myColors&#123; &#123;0,87,54,15,205,245&#125;,//橙色（hmin smin vmin hmax smax vmax）\t\t\t\t\t\t\t\t&#123;0,0,0,0,0,0&#125; &#125;;//绿色（hmin smin vmin hmax smax vmax）//RGB颜色空间vector&lt;Scalar&gt; myColorValues&#123; &#123;255,0,255&#125;,//蓝色\t\t\t\t\t\t\t\t&#123;0,255,0&#125; &#125;;//绿色\n绘制void drawOnCanvas(vector&lt;vector&lt;int&gt;&gt; newPoints, vector&lt;Scalar&gt; myColorValues) &#123;\tfor (int i = 1; i &lt; newPoints.size(); i++) &#123;\t\tline(img, Point(newPoints[i - 1][0], newPoints[i - 1][1]), Point(newPoints[i][0], newPoints[i][1]), Scalar(0, 255, 255), 10);\t&#125;&#125;//把 newPoints[i- 1] 和 newPoints[i] 连起来\nline\nvoid line(Mat&amp; img, Point pt1, Point pt2, const Scalar&amp; color, int thickness=1, int lineType=8, int shift=0)//img 要绘制线段的图像//pt1 线段的起点//pt2 线段的终点//color 线段的颜色 Scalar对象定义//thickness 线条的宽度//lineType 线段的类型 8(默认)/4/CV_AA(高斯滤波)//shift 坐标点小数点位数\n颜色过滤 &amp; 寻找对象vector&lt;vector&lt;int&gt;&gt; findColor(Mat img) &#123;\tMat imgHSV;\tcvtColor(img, imgHSV, COLOR_BGR2HSV);//转换图像到HSV空间，在其中查找颜色更加容易\tfor (int i = 0; i &lt; myColors.size(); i++)\t&#123;\t\tScalar lower(myColors[i][0], myColors[i][1], myColors[i][2]);\t\tScalar upper(myColors[i][3], myColors[i][4], myColors[i][5]);\t\tMat mask;\t\tinRange(imgHSV, lower, upper, mask);//定义颜色下限和上限，因为由于照明和不同的阴影，颜色的值将不完全相同，会是一个值的范围\t\t//imshow(to_string(i), mask);\t\tPoint myPoint = getContours(mask);\t\tif (myPoint.x != 0 &amp;&amp; myPoint.y != 0) &#123;//没检测到东西的时候就不加入新点\t\t\tnewPoints.push_back(&#123; myPoint.x,myPoint.y,i &#125;);//i为颜色索引\t\t&#125;\t&#125;\treturn newPoints;//返回检测到物体轮廓的点集&#125;\nScalar\ntypedef struct Scalar&#123;    double val[4];&#125;Scalar;\n将各个通道的值构成一个整体\n\n越看代码越觉得眼熟，欢迎回到前面的博客（bilibili教程代码——project1）\n（我说怎么写代码写这么多注释……\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"OpenCV (相机标定)","url":"/2021/07/31/OPENCV1-3/","content":"“The moment you doubt whether you can fly, you cease for ever to be able to do it.” —— Peter Pan\n\nPr相机标定相机参数的估计过程称为相机标定。这意味着我们拥有关于相机的所有信息（参数或系数），这些信息用于确定真实世界中的) 3D 点与其在该标定相机捕获的图像中的相应 2D 投影（像素）之间的精确关系。通常这意味着恢复两种参数。\n内部参数: 例如透镜的焦距、光学中心和径向畸变系数。外部参数: 指相机相对于某些世界坐标系的方位(旋转和平移)。\n二维点与三维点的转化\n\\pmb{s}\n\\begin{vmatrix} \n\\pmb{x} \\\\ \\pmb{y} \\\\ \\pmb{1}\n\\end{vmatrix}\n = \n\\begin{vmatrix} \n\\pmb{f} & \\pmb{0} & \\pmb{0} & \\pmb{0} \\\\ \\pmb{0} & \\pmb{f} & \\pmb{0} & \\pmb{0} \\\\ \\pmb{0} & \\pmb{0} & \\pmb{1} & \\pmb{0}\n\\end{vmatrix}\n\n\\begin{vmatrix} \n\\pmb{X} \\\\ \\pmb{Y} \\\\ \\pmb{Z} \\\\ \\pmb{1}\n\\end{vmatrix}四种坐标系\n1、图像像素坐标系：表示场景中三维点在图像平面上的投影，其坐标原点在CCD图像平面的左上角，u轴平行于CCD平面水平向右，v轴垂直于u轴向下，坐标使用（u,v）来表示。注：这里的（u,v）表示的是该像素在数组中的列数和行数\n2、图像物理坐标系：其坐标原点在CCD图像平面的中心，x,y轴分别平行于图像像素坐标系的坐标轴，坐标用(x,y)表示。\n3、相机坐标系：以相机的光心为坐标系原点，X,Y轴平行于图像坐标系的X,Y轴，相机的光轴为Z轴，坐标系满足右手法则。注：这里所指的相机的光心可以简单的理解为相机透镜的几何中心\n4、世界坐标系：也称为绝对坐标系，用于表示场景点的绝对坐标\n世界参考系和相机参考系的转换https://blog.csdn.net/jiangxing11/article/details/106478020\nhttps://blog.csdn.net/qq_15029743/article/details/90215104\n投影方程\n\\pmb{s}\n\\begin{vmatrix} \n\\pmb{x} \\\\ \\pmb{y} \\\\ \\pmb{1}\n\\end{vmatrix}\n = \n\\begin{vmatrix} \n\\pmb{f_x} & \\pmb{0} & \\pmb{u_0} \\\\ \\pmb{0} & \\pmb{f_y} & \\pmb{v_0} \\\\ \\pmb{0} & \\pmb{0} & \\pmb{1}\n\\end{vmatrix}\n\n\\begin{vmatrix} \n\\pmb{r_1} & \\pmb{r_2} & \\pmb{r_3} & \\pmb{t_1} \\\\ \\pmb{r_4} & \\pmb{r_5} & \\pmb{r_6} & \\pmb{t_2} \\\\ \\pmb{r_7} & \\pmb{r_8} & \\pmb{r_9} & \\pmb{t_3}\n\\end{vmatrix}\n\n\\begin{vmatrix} \n\\pmb{X} \\\\ \\pmb{Y} \\\\ \\pmb{Z} \\\\ \\pmb{1}\n\\end{vmatrix}基于OpenCV的相机标定目标标定过程的目标是使用一组已知的三维点 $(X_w, Y_w, A_w)$ 及其对应的图像坐标 $(u, v)$\n找到 3×3矩阵 K , 3×3旋转矩阵 R , 3×1平移向量 T 。当我们得到相机的内部和外部参数值时，相机就被称为标定相机。\n总之，相机标定算法具有以下输入和输出：\n输入：具有已知二维图像坐标和三维世界坐标的点的图像集合。输出：3×3相机内参矩阵，每幅图像的旋转和平移。注意OpenCV中，相机内部矩阵不包含倾斜参数。所以矩阵的形式是：\n\n\\begin{vmatrix} \n\\pmb{f_x} & \\pmb{0} & \\pmb{c_x} \\\\ \\pmb{0} & \\pmb{f_y} & \\pmb{c_y} \\\\ \\pmb{0} & \\pmb{0} & \\pmb{1}\n\\end{vmatrix}方法\n校正：当我们完全控制成像过程时，执行校准的最佳方法是从不同的视角捕获一个物体或已知尺寸模式的多个图像。我们将在这篇文章中学习的基于棋盘的方法属于这一类。我们也可以使用已知尺寸的圆形图案，而不是棋盘格图案。\n几何线索：有时我们在场景中有其他的几何线索，如直线和消失点，可以用来标定。\n基于深度学习的：当我们对成像设置的控制非常小（例如，我们有场景的单个图像）时，仍然可以使用基于深度学习的方法获取相机的校准信息。\n\n步骤\n使用棋盘格模式定义真实世界坐标;\n从不同的角度捕获棋盘的多个图像;\n查找棋盘的2D坐标;\n校准相机\n\n实现OpenCV 推荐使用国际象棋棋盘的图案生成用于标定的三维场景点的集合。\n\n这个图案在每个方块的角点位置创建场景点；由于图案是平面的，可以假设棋盘位于 Z = 0,  X,Y 的坐标轴与网格对其的位置 。这样，标定时就只需从不同的视角拍摄棋盘图案。\n\n检测角点\n可以用OpenCV自带的函数自动检测棋盘图案中的角点。只需要提供一幅图像和棋盘尺寸（水平和垂直方向内部角点的数量），函数会返回图像中所有棋盘角点的位置，若无法找到图案，函数返回false。\n//输出图像角点的向量vector&lt;Point2f&gt; imageCorners;//棋盘内部角点的数量Size boardSize(7, 5);//获得棋盘角点bool foound = findChessboardCorners(image, boardSize, omageCorners);//image 棋盘图案\n棋盘内部角点数，如图\n\n画角点\n画出角点并用线条连接起来，连接次序即在想两种存储的次序。\ndrawChessboardCorners(image, boardSize, imageCorners, found);\n\n指定三维点\n自由选择单位，如厘米或英寸等。\n为了方便起见我们将方块的边长定位单位，这样可令点的坐标如 （0，0，0）（6，4，0） 这样便于表示。\n（假设棋盘纵深坐标为 z = 0 ）\n为了得到更多的点，需要从不同的视角对同一个标定图案拍摄更多的照片。\nOpenCV的标定函数假定由标定图案确定坐标系，并计算相机相对于坐标系的旋转量和平移量。\n把标定过程封装在 CameraCailbrator 中，\nclass CameraCailbrator&#123;    //每个向量的元素也是一个向量 表示一个视角的点集    //输入点 世界坐标系（每个正方形为一个单位）    vector&lt;vector&lt;Point3f&gt; &gt; objectPoints;    //点在图像中的位置（以像素为单位）    vector&lt;vector&lt;Point2f&gt; &gt; imagePoints;    //输出矩阵    Mat cameraMatrix;    Mat distCoeffs;    //指定标定方式的标志    int fllag;&#125;\n\n类库\n#ifndef CAMERACALIBRATOR_H#define CAMERACALIBRATOR_H#include &lt;vector&gt;#include &lt;iostream&gt;#include &lt;opencv2/core.hpp&gt;#include &quot;opencv2/imgproc.hpp&quot;#include &quot;opencv2/calib3d.hpp&quot;#include &lt;opencv2/highgui.hpp&gt;class CameraCalibrator &#123;    // 输入点：      // 世界坐标系中的点     //（每个正方形为一个单位）     std::vector&lt;std::vector&lt;cv::Point3f&gt; &gt; objectPoints;    // 点在图像中的位置（以像素为单位）     std::vector&lt;std::vector&lt;cv::Point2f&gt; &gt; imagePoints;    // 输出矩阵     cv::Mat cameraMatrix;    cv::Mat distCoeffs;    // 指定标定方式的标志    int flag;    // used in image undistortion     cv::Mat map1,map2;     bool mustInitUndistort;  public:    CameraCalibrator() : flag(0), mustInitUndistort(true) &#123;&#125;    // Open the chessboard images and extract corner points    int addChessboardPoints(const std::vector&lt;std::string&gt;&amp; filelist, cv::Size &amp; boardSize, std::string windowName=&quot;&quot;);    // Add scene points and corresponding image points    void addPoints(const std::vector&lt;cv::Point2f&gt;&amp; imageCorners, const std::vector&lt;cv::Point3f&gt;&amp; objectCorners);    // Calibrate the camera    double calibrate(const cv::Size imageSize);    // Set the calibration flag    void setCalibrationFlag(bool radial8CoeffEnabled=false, bool tangentialParamEnabled=false);    // Remove distortion in an image (after calibration)    cv::Mat remap(const cv::Mat &amp;image, cv::Size &amp;outputSize = cv::Size(-1, -1));    // Getters    cv::Mat getCameraMatrix() &#123; return cameraMatrix; &#125;    cv::Mat getDistCoeffs()   &#123; return distCoeffs; &#125;&#125;;#endif // CAMERACALIBRATOR_H\n\n这里采用增加标定点的方法\nint CameraCailbrator::addChessboardPoints(const vector&lt;string&gt; &amp; filelist, Size &amp; boardSize)&#123; //文件名列表 标定面板大小        //棋盘上的角点    vector&lt;Point2f&gt; imageCorners;    vector&lt;Point3f&gt; objectCorners;        //场景中的三维点 在棋盘坐标系中，初始化期盼中的角点 角点的三维坐标(i, j, 0)    for(int i = 0; i &lt; boardSize.height; ++i)&#123;        for(int j = 0; j &lt; boardSize.width; ++j)&#123;            objectCorners.push_back(Point3f(i, j, 0.0f));        &#125;    &#125;        //图像中的二维点    Mat image; //存储棋盘图像    int successes = 0;    //处理所有视角    for(int i = 0; i &lt; filelist.size(); ++i)&#123;        image = imread(filelist[i], 0);                bool found = findChessboardCorners(image, boardSize, imageCorners);                //取得角点上的亚像素级精度        if(found)&#123;            cornerSubPix(image, imageCorners, Size(5, 5), Size(-1, -1), TermCriteria(TermCriteria::MAX_ITER + TermCriteria::EPS, 30, 0.1));            //棋盘完好            if(imageCorners.size() == boardSize.area())&#123;                //加入同一视角得到的图像和场景点                addPoints(imageCorners, objectCorners);                successes++;            &#125;        &#125;    &#125;    return successes; &#125;\n处理完足够数量的棋盘图像（一般10~20个）后，就可以开始计算标定参数了\n//标定相机 返回重投影误差double CameraCalibrator::calibrate(Size &amp;imageSize)&#123;    //输出旋转量和平移量     vector&lt;Mat&gt; rvecs, tvecs;        //开始标定    return calibrateCamera(objectPoints, // 三维点                           imagePoints,  // 图像点                           imageSize,    // 图像尺寸                           cameraMatrix, // 输出相机矩阵                           distCoffes,   // 输出畸变矩阵                           rvecs, tvecs, // Rs，Ts                           flag);        // 设置选项&#125;\n重投影误差\n函数 calibrateCamera 在得到标定结果之前进行了优化，以便找到合适的内部参数和外部参数，使图像点的预定位置（根据三维点的投影计算得到）和实际位置（图像中的位置）之间的距离达到最小。每个点在标定过程中都会产生这个距离，它们的累加和就是重投影误差。\n畸变模型\n径向畸变：超广角镜头产生的典型畸变\n// 去除图像中的畸变（标定后）Mat CameraCalibrator::remap(const Mat &amp;image)&#123;    Mat undistorted;        if(mustInitUndistort)&#123; // 每个标定过程只调用一次                initUndistortRectifyMap(cameraMatrix, // 计算得到的相机矩阵                                distCoeffs,   // 计算得到的畸变矩阵                                Mat(),        // 可选矫正项（无）                                Mat(),        // 生成无畸变的相机矩阵                                image.size(), // 无畸变图像的尺寸                                CV_32FC1,     // 输出图片的类型                                map1, map2);  // x和y映射功能                mustInitUndistort = false;    &#125;    // 应用映射功能    remap(image, undistorted, map1, map2, INTER_LINEAR); // 插值类型        return undistorted;&#125;\n实现原理回到本文最前面的投影方程。\n方程中连续使用了两个矩阵，把三维空间的点转换到二维空间。\n第一个矩阵，相机的内部参数，是一个3*3的矩阵。是函数 calibrateCamera 输出的矩阵之一。此外还有一个 calibrationMatrixValues 函数，它根据标定矩阵，显示地返回内部参数值。\n第二个矩阵，外部参数，内容是输入的点，以相机为坐标系中心。它由一个旋转向量（3*3）和一个平移向量（3*1）组成。旋转向量 $r_1, r_2, … r_9$ ，平移向量 $t_1, t_2, t_3$ 。\n参考https://blog.csdn.net/LuohenYJ/article/details/104697062\nhttps://blog.csdn.net/jiangxing11/article/details/106478020\nhttps://blog.csdn.net/qq_15029743/article/details/90215104\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"OpenCV (相机姿态还原)","url":"/2021/08/02/OPENCV1-4/","content":"在已知物体三维结构的情况下，如何计算出相机的姿态。\n\n三维姿态solvePnP官方解释：\nhttp://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#solvepnp\nbool solvePnP(InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec,bool useExtrinsicGuess=false, int flags=ITERATIVE )\n注意，OpenCV 中还提供了 SolvePnPRansac 函数。它使用 RANSAC 算法求解 PnP 问题。这个函数能识别出错误的物体点/图像点对，并将其标记为异常数据。\nRANSAC（随机抽样一致性）\n用于匹配图像的算法\nhttps://zhuanlan.zhihu.com/p/45532306\nhttps://blog.csdn.net/weixin_42990464/article/details/119254747\ncvPOSIT官方解释：\nhttp://www.opencv.org.cn/index.php/Cv%E7%85%A7%E7%9B%B8%E6%9C%BA%E5%AE%9A%E6%A0%87%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA#POSIT\nvoid cvPOSIT( CvPOSITObject* posit_object, CvPoint2D32f* image_points, double focal_length, CvTermCriteria criteria, CvMatr32f rotation_matrix,  CvVect32f translation_vector )\n两种函数的同与异同：\n\n输入都是 3D 点集和对应的 2D 点集，其中 cvPOSIT 的 3D 点包含在 posit_object 结构中\n输出包括旋转矩阵和位移向量\n\n异：\n\nsolvePnP 调用的是 cvFindExtrinsicCameraParams2 通过已知的内参进行未知外参求解，是一个精确解；而 cvPOSIT 是用仿射投影模型近似透视投影模型下，不断迭代计算出来的估计值(在物体深度变化相对于物体到摄像机的距离比较大的时候,这种算法可能不收敛)\nsolvePnP 输出的 rvec 是旋转向量，可以通过 Rodrigues 转换成旋转矩阵，有需要可以再转到欧拉角\n\n实现公园里的长椅\n用标定的相机进行拍照 并 标注8个点\n测量长椅的物理尺寸\n椅座：242.5cm53.5cm\\9cm\n靠背：242.5cm24cm\\9cm\n两者相距 12cm\n\n推导八个点的三维坐标设椅座与靠背的交叉线的左侧顶点作为坐标系原点\nvector&lt;Point3f&gt; objectPoints;objectPoints.push_back(Point3f(0, 45, 0));objectPoints.push_back(Point3f(242.5, 45, 0));objectPoints.push_back(Point3f(242.5, 21, 0));objectPoints.push_back(Point3f(0, 32, 0));objectPoints.push_back(Point3f(0, 9, -9));objectPoints.push_back(Point3f(242.5, 9, -9));objectPoints.push_back(Point3f(242.5, 9, 44.5));objectPoints.push_back(Point3f(0, 9, 44.5));\n在二维成像平面中，写出这些点的坐标vector&lt;Point2f&gt; imagePoints;objectPoints.push_back(Point2f(136,113));objectPoints.push_back(Point2f(379,114));objectPoints.push_back(Point2f(379,150));objectPoints.push_back(Point2f(138,135));objectPoints.push_back(Point2f(143,146));objectPoints.push_back(Point2f(381,166));objectPoints.push_back(Point2f(345,194));objectPoints.push_back(Point2f(103,161));\n调用 solvePnP 函数，计算拍照时相机与这些点之间的相对位置此函数实际上是通过旋转和平移，把物体坐标转换到以相机为中心的坐标系上（焦点为坐标原点）\n注意，该函数得到的旋转量是一个三维容器。表示物体绕着一个单位向量（旋转轴）转了某个角度。（轴 + 角度，罗德里格旋转公式 ）。在 OpenCV 中，旋转角度对应着输出的旋转向量的值，该向量与旋转轴一致，所以，投影公式中使用 Rodrigues 函数来获取旋转三维矩阵。\nMat rvec, tvec;solvePnP(objectPoints, imagePoints, // 对应的三维点和二维点         cameraMatrix, cameraDistCoeffs, // 标定（相机内参 和 相机畸变）         rvec, tvec); // 输出// 转换成三维旋转矩阵Mat rotation;Rodrigues(rvec, rotation);\n检验使用 cv::viz 模块可以显示三维信 息\ncv::viz:: ...\n使用样例\ncv::viz::Viz3d visualizer(&quot;Viz window&quot;); // 创建窗口visualizer.setBackgroundColor(cv::viz::Color::white()); // 白色背景// 创建一个虚拟相机cv::viz::WCameraPosition cam(cMatrix, // 内部参数矩阵 类型为Matx33d（Matx&lt;double, 3, 3&gt;                            image, // 平面上显示的图像                            30.0, // 缩放因子                            cv::viz::Color::black());// 在环境中添加虚拟相机visualizer.showWidget(&quot;Camera&quot;, cam);// 用长方形表示虚拟的长椅cv::viz::Wcube plane1(Point3f(0.0, 45.0, 0.0),                     Point3f(242.5, 21.0, -9.0),                     true, // 显示线条框架                     cv::viz::Color::blue());cv::viz::Wcube plane2(Point3f(0.0, 9.0, -9.0),                     Point3f(242.5, 0.0, 44.5),                     true, // 显示线条框架                     cv::viz::Color::blue());// 把虚拟物体加入到环境中visualizer.showWidget(&quot;top&quot;, plane1);visualizer.showWidget(&quot;bottom&quot;, plane2);// 虚拟长椅也放在坐标原点，然后用cv::solvePnP函数计算出以相机为中心的位置，并把长椅移动到该位置。这个过程在setWidgetPose方法中完成。这里只是根据估算值进行了旋转和平移Mat rotation;// 将rotation转换成3*3的旋转矩阵Rodrigues(rvec, rotation);// 移动长椅Affine3d pose(rotation, tvec);visualizer.setWidgetPose(&quot;top&quot;, pose);visualizer.setWidgetPose(&quot;bottom&quot;, pose);// 循环显示while(waitKey(100) == -1 &amp;&amp; !visualizer.wasStopped())&#123;        visualizer.spinOnce(1, // 暂停1s                       true); // 重绘&#125;// 关闭可视化窗口 或 在OpenCV图像窗口上输入任意键就可以结束循环。在循环内部移动物体（用setWidgetPose），即可产生动画。\n相机姿态更新https://blog.csdn.net/aptx704610875/article/details/48915149\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"OpenCV (用标定相机实现三维重建)","url":"/2021/08/02/OPENCV1-5/","content":"  利用不同视角下图像点之间的关系，计算出三维信息。\n\n学些啥？\n利用不同视角下图像点之间的关系，计算出三维信息\n\n新的数学实体 —— 本质矩阵\n\n三角剖分概念\n\n\n\n实现匹配两个视图的特征点可利用 SIFT检测器 或 描述子\nSIFT &amp; SURFSURF（加速稳健特征） 算法是 SIFT（尺度不变特征转换） 算法的加速版\nSURF 特征检测属于 opencv_contrib 库，在编译时包含了附加模块才能使用。\n// 创建SURF特征检测器对象Ptr&lt;xfeatures2d::SurfFeatureDetector&gt; ptrSURF = xfeatures2d::SurfFeatureDetector::create((2000.0));// 检测关键点ptrSURF -&gt; detect(image, keypoints);\nSIFT\n// 创建SIFT特征检测器对象Ptr&lt;xfeatures2d::SiftFeatureDetector&gt; ptrSIFT = xfeatures2d::SiftFeatureDetector::create((2000.0));// 检测关键点ptrSIFT -&gt; detect(image, keypoints);\n画关键点\ndrawKeypoints(image,                                  // 原始图像              keypoints,                              // 关键点的向量              featureImage,                           // 结果图像              Scalar(255, 255, 255),                  // 点的颜色              DrawMatchesFlags::DRAW_RICH_KEYPOINTS); // 显示相关的因子尺度\n包含被检测特征的结果图像\n\n用不同的尺度对同一物体拍摄一张照片，特征检测的结果图像\n\n DrawMatchesFlags::DRAW_RICH_KEYPOINTS 标志得到了关键点的圆，并且圆的尺寸与每个特征计算得到的尺度成正比。为了使特征具有旋转不变性，SURF还让每个特征关联了一个方向，由每个圆的辐射线表示。\n特征描述子// 定义关键点的容器vector&lt;KeyPoint&gt; keypoints1;vector&lt;KeyPoint&gt; keypoints2;// 定义特征检测器Ptr&lt;Feature2D&gt; ptrFeature2D = xfeatures2d::SURF::create(2000.0);// 检测关键点ptrFeature2D -&gt; detect(image1, keypoints1);ptrFeature2D -&gt; detect(image2, keypoints2);// 提取描述子Mat descriptors1;Mat descriptors2;ptrFeature2D -&gt; compute(image1, keypoints1, descriptors1);ptrFeature2D -&gt; compute(image2, keypoints2, descriptors2);// 构造匹配器BFMatcher matcher(NORM_L2);// 匹配两幅图像的描述子vector&lt;DMatch&gt; matches;matcher.match(descriptors1, descriptors2, matches);\nFeature2D 类有一个很实用的函数，可在检测兴趣点的同时计算它们的描述子，调用方法如下\nptrFeature2D -&gt; detectAndCompute(image, noArray(), keypoints, descriptors);\n二值描述子ORB\nORB 的用法与 SURF 、SIFT 没有什么区别\n// 定义关键点的容器 和 描述子vector&lt;KeyPoint&gt; keypoints1;vector&lt;KeyPoint&gt; keypoints2;Mat descriptors1;Mat descriptors2;// 定义特征检测器 / 描述子Ptr&lt;Feature2D&gt; feature = ORB::create(60);// 检测 并 描述 关键点feature -&gt; detectAndCompute(image1, noArray(), keypoints1, descriptors1);feature -&gt; detectAndCompute(image2, noArray(), keypoints2, descriptors2);// 构造匹配器BFMatcher matcher(NORM_HAMMING); // 二值描述子一律用HAMMING规范// 匹配两幅图像的描述子vector&lt;DMatch&gt; matches;matcher.match(descriptors1, descriptors2, matches);\n找出本质矩阵https://www.cnblogs.com/yuanlibin/p/9462180.html\nMat inliers;Mat essential findEssentialMat(points1, points2,                              Matrix, // 内部参数                              RANSAC,                              0.9, 1.0, // RANSAC方法                              inliers); // 提取到的内殿\n还原相机的相对姿态// 根据本质矩阵还原相机的相对姿态Mat rotation, trnslation;recoverPose(essential, // 本质矩阵            points1, points2, // 匹配的关键点            cameraMatrix, // 内部矩阵            rotation, translation, // 计算的移动值            inliers); // 内点匹配项\n计算三角剖分vector&lt;Vec3d&gt; points3D;triangulate(projection1, projection2, points1u, points2u, points3D);\n\n完整代码// 定义关键点的容器 和 描述子vector&lt;KeyPoint&gt; keypoints1;vector&lt;KeyPoint&gt; keypoints2;Mat descriptors1;Mat descriptors2;// 定义SIFT特征检测器Ptr&lt;Feature2D&gt; ptrFeature2D = xfeatures2d::SIFT::create(500);// 检测 并 描述 关键点feature -&gt; detectAndCompute(image1, noArray(), keypoints1, descriptors1);feature -&gt; detectAndCompute(image2, noArray(), keypoints2, descriptors2);// 构造匹配器BFMatcher matcher(NORM_L2, true); // 交叉检查标志 true// 匹配两幅图像的描述子vector&lt;DMatch&gt; matches;matcher.match(descriptors1, descriptors2, matches);// 将关键点转换成 Point2f 类型vector&lt;Point2f&gt; points1, points2;for(vector&lt;DMatch&gt;::const_iterator it = matches.begin(); it!= matches.end(); ++it)&#123;    // 获取 左 右 侧关键点的位置    float x = keypoints1[it -&gt; queryIdx].pt.x;    float y = keypoints1[it -&gt; queryIdx].pt.y;    points1.push_back(Point2f(x, y));        float x = keypoints2[it -&gt; queryIdx].pt.x;    float y = keypoints2[it -&gt; queryIdx].pt.y;    points2.push_back(Point2f(x, y));&#125;// 找出image1，image2之间的本质矩阵Mat inliers;Mat essential findEssentialMat(points1, points2,                              Matrix, // 内部参数                              RANSAC,                              0.9, 1.0, // RANSAC方法                              inliers); // 提取到的内殿// 根据本质矩阵还原相机的相对姿态Mat rotation, trnslation;recoverPose(essential, // 本质矩阵            points1, points2, // 匹配的关键点            cameraMatrix, // 内部矩阵            rotation, translation, // 计算的移动值            inliers); // 内点匹配项// 根据旋转量R和平移量T构建投影矩阵Mat projection2(3, 4, CV_64F); // 3*4rotation.copyTo(projection2(Rect(0, 0, 3, 3)));translation.copyTo(projection2.colRange(3, 4));// 构建通用投影矩阵Mat projection1(3, 4, CV_64F, 0);Mat diag(Mat::eye(3, 3, CV_64F));diag.copyTo(projection1(Rect(0, 0, 3, 3)));// 用于存储内点vector&lt;Vec2d&gt; inlierPts1;vector&lt;Vec2d&gt; inlierPts2;// 创建输入内点的容器，用于三角剖分int j(0);for(int i = 0; i &lt; inliers.rows; ++i)&#123;    if(inliers.at&lt;uchar&gt;(i))&#123;    \tinlierPts1.push_back(Vec2d(points1[i].x, points1[i].y));        inlierPts2.push_back(Vec2d(points2[i].x, points2[i].y));    &#125;&#125;// 矫正并标准化图像点vector&lt;Vec2d&gt; points1u;undistortPoints(inlierPts1, points1u, cameraMatrix, cameraDistCoeffs);vector&lt;Vec2d&gt; points2u;undistortPoints(inlierPts2, points2u, cameraMatrix, cameraDistCoeffs);// 三角剖分vector&lt;Vec3d&gt; points3D;triangulate(projection1, projection2, points1u, points2u,)\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"Speech_subwayMusician","url":"/2021/07/31/Speech-subwayMusician/","content":"是演讲集训了~\n\nAt a subway station in Washington D.C., a few people stop their feet to enjoy even to listen to the music composed by the world’s top musicians during the morning rush hour. The story is kind of ridiculous but it really happens in our daily life. People get up, rush out the door and throw themselves into busy work without a second thought. People nowadays do lack of eyes to discover beauty, do lack of ears to listen to nature and do lack of heart to enjoy life itself.\nA few days ago, one of my classmates texted me telling me how anxious she was. Being a freshman learning computer science and technology, she not only become a night owl, but also need to get up early in the morning. She learns very hard but the outcome made her doubt the value of herself and the beauty of her life. I took her to a park nearby. After that she changed her attitude towards life, being delighted and hopeful.\nThe world never lack of beauty and hope. But people shut their ears, totally immerse in busy work even the work brings bitter and complain why life is so tough. People have no time stopping their feet even a little while. However there are still a group of people who devote themselves to slow down the life pace like the musician in Washington D.C..\nThe world is so beautiful. It integrates all kinds of people. Some rush forward to make the world a better place, others try to slow down their pace to make spiritual world a more peaceful place.\nDon’t stop for too long. Don’t go too fast. Open your heart, feeling the beautiful world around you. thank you.\n","categories":["HDU's Learning"],"tags":["English speech"]},{"title":"OpenCV代码目录","url":"/2021/08/03/codesToc/","content":"搬！\n\nChapter01\nChapter02\nChapter03\nChapter04\nChapter05\nChapter06\nChapter07\nChapter08\nChapter09\nChapter10\nChapter11\nChapter12\nChapter13\nChapter14\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"Hello World","url":"/2021/01/17/hello-world/","content":"Welcome to Hexo! \n\nThis is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\nMore info: Writing\nRun server$ hexo server\nMore info: Server\nGenerate static files$ hexo generate\nMore info: Generating\nDeploy to remote sites$ hexo deploy\nMore info: Deployment\n","tags":["other"]},{"title":"pronounciation","url":"/2021/08/03/pronounciation/","content":"I saw the most beautiful thing ever one morning.\nIt was early with a slight frost on the ground,\nand I was walking on dewy grass down to the horse paddocks\n- my mind on the days chores.\nSuddenly a blazing laser flash erupted straight from the ground about 15 feet in front of me,\nand shot up into the sky.\nIt was so brilliant, clear and clean, it literally topped me in my tracks.\nI thought the only thing that could make such a dazzling flash must be a diamond\n- maybe someone had lost some kind of jewelry.\nOr some kind of weird reverse lightning strike\n- so bright.\nI waited to see if it repeated but it didn’t.\nI walked slowly towards it.\nThere was nothing to see.\nI stared down at the grass,\nsearching for a glint of gold or some kind of metal.\nNothing.\nSo I dropped down really close and there it was!\nA tiny - no bigger than a dime - trapdoor spider’s web,\ndelicately hanging between blades of grass,\nglistening with miniature drops of dew,\nflashing and twinkling in a myriad of colors.\nThe rising sun had caught the exact angle of the dewdrops,\nand that laser light had exploded up into the sky.\nIt was incredible and stunning,\nsuch a powerful flash from something so small and fragile,\nand I would have crushed it beneath my feet.\nIt was as though the unseen world was giving me a heads-up.\nHello! Look what’s around you.\nI’ve never forgotten that moment.\nSo I say to everyone-\ntake some time to notice the miracle of nature that most of us never even see.\nSo much beauty all around us if we would only take the time.\nLook at the brilliant colors and intricate patterns of tiny flowers that cover playing fields\n- we walk all over them without a second glance.\nWatch a bee harvesting pollen .\nSo busy with a purpose.\nTiny ants going about their day.\nBirds singing and fluffing their wings, being bossy.\nBusy iridescent beetles and glossy lizards.\nThe subtle shading and colors of practically any flower on earth are breathtaking and all natural\n- if we would only notice.\nIt doesn’t have to be a garden.\nIt can even be a weed flowering in the pavement crack.\nSo I say -\ntake the time\nand each day discover from nature one secret beautiful thing that you can keep in your heart.\nAnd get your children to do the same.\nTake a picture.\nit’s what life really consists of.\nAnd it’s free.\n","categories":["HDU's Learning"],"tags":["English speech"]},{"title":"写博客","url":"/2021/01/18/%E5%86%99%E5%8D%9A%E5%AE%A2/","content":"Colin 教我写博客\n\n打广告 Colin’s Space\ncmd\n$ d:$ cd blog$ cd blog711$ hexo new posts haha$ hexo g$ hexo sctrl + cY$ hexo clean$ exit\n","categories":["HDU's Life"],"tags":["other"]},{"title":"无问西东","url":"/2021/07/29/%E6%97%A0%E9%97%AE%E8%A5%BF%E4%B8%9C/","content":"一路走来，一路盛开\n\n经典语录\n如果提前了解了你们要面对的人生，不知道你们是否还会有勇气前来。\n这个世界缺的不是完美的人，而是从心底给出的真心，正义，无畏与同情。\n看到和听到的，经常会令你们沮丧，世俗是这样强大，强大到生不出改变它们的念头来。可是如果有机会提前了解了你们的人生，知道青春也不过只有这些日子，不知你们是否还会在意那些世俗希望你们在意的事情。比如占有多少才更荣耀，拥有什么才能被爱。\n等你们长大，你们会因绿芽冒出土地而喜悦，会对初升的朝阳欢呼跳跃。也会给别人善意和温暖。但是却会在赞美别的生命的同时，常常，甚至永远地忘了自己的珍贵。愿你在被打击时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵，爱你所爱，行你所行，听从你心，无问西东。\n什么是真实？你看到什么，听到什么，做什么，和谁在一起。有一种从心灵深处满溢出来的不懊悔，也不羞耻的和平与喜悦。\n人把自己置身于忙碌之中，有一种麻木的踏实，但丧失了真实，你的青春不过只有这些日子。\n那一刻，我从思索生命意义的羞耻感中释放出来，希望你们今后的岁月里，不要放弃对生命的思索，对自己的真实。\n世界于你而言，毫无意义和目的，却又充满随心所欲的幻想。但又有谁知，也许就在这闷热令人疲倦的正午，那个陌生人，提着满篮奇妙的货物，路过你的门前，他响亮的叫卖着，你就会从朦胧的梦中惊醒，走出房门，迎接命运的安排——《泰戈尔的诗》。\n你别怕，我就是那个给你托底的人，我会跟你一起往下掉。不管掉得有多深，我都会在下面给你托着。我最怕的是，掉的时候你把我推开，不让我给你托着。\n他们的爱与风华，只问自由，只问盛放，只问深情，只问初心，只问勇敢，无问西东。\n你怪她没有真实，你给她真实的力量了吗？\n逝者已矣，生者如斯，对以后的人好吧。\n一生太短，一瞬好长，我们哭着醒来，又哭着遗忘。\n\n观后感什么是真正的平淡？真正的平淡是指，生命中曾经历过轰轰烈烈与刻骨铭心后，才感悟到平淡的可贵。而不是一生碌碌无为，却安慰自己平凡是真。\n电影前前后后讲了四个时代的故事，四个不同时代的年轻人分别做出了自己的选择。\n吴岭澜听了泰戈尔的演讲后，遵从本心选择了文学之路；沈光耀从军牺牲；被诬陷险些丧生王敏佳、边防献身者李想、核事业贡献者陈鹏；张果果真心帮助四胞胎一家，并拒绝 robert 的提议。\n他们做出无悔选择，结局或好或坏，终究死而无憾。\n坚持初心 &amp;&amp; 传递爱\n不忘初心，方得始终，念念不忘，必有回响。\n","categories":["HDU's Life"],"tags":["movie"]},{"title":"银河补习班","url":"/2021/07/30/%E9%93%B6%E6%B2%B3%E8%A1%A5%E4%B9%A0%E7%8F%AD/","content":"白驹过隙，将梦想藏在裙子里\n\n马皓文因一次意外事故而入狱，让他遗憾地错过了儿子七年的成长时光。用自己独特的教育方法和满满的爱给予儿子马飞自由成长的空间，教会儿子独立思考的能力和面对困难的勇气。\n台词集\n\n当你能够做到自己身处黑暗之中，还能把光明留给别人，你就是一个成年人了。\n不，他人生最重要的时刻，一定是均匀散在每一天。\n人生就像射箭，梦想就像箭靶子。如果箭靶子都找不到，你每天张弓有什么意义。\n该冒的险，我是不会错过的。\n永远不要停止思考，永远不要服输。只要你不害怕，没有人，能挡住你的去向。\n\n","categories":["HDU's Life"],"tags":["movie"]},{"title":"OpenCV (视频读写&&背景消去&&对象跟踪)","url":"/2021/07/28/OPENCV1-1/","content":"这是Eva今年暑假学的~\n\nChapter 1 视频读写#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main(/*int argc, char** argv*/)&#123; //括号里应该不重要吧\tVideoCapture capture;\tcapture.open(&quot;D:/.../&quot;);         //要打开的文件的路径\tif(!capture.isOpened())&#123;         //如果打开失败了\t\tcout &lt;&lt; &quot;could not load&quot; &lt;&lt; endl;\t\treturn -1; \t&#125;\t\tdouble fps = capture.get(CV_CAP_PROP_FPS);\tVedioWriter writer(&quot;...&quot;, -1, fps, Size(640, 480), true);\t//Size size = Size(capture.get(CV_CAP_PROP_FRAME_WIDTH), capture.get(CV_CAP_PROP_FRAME_HEIGHT));\t\tMat frame, gray, binary;\tnamedWindow(&quot;Video-demo&quot;, CV_WINDOW_AUTOSIZE);\twhile(capture.read(frame))&#123;\t\t//imshow(&quot;Video-demo&quot;, frame);\t\t//cvtColor(frame, gray, COLOR_BGR2GRAY);        //转换成灰度图\t\t//imshow(&quot;Video-demo&quot;, gray);\t\t//threshold(gray, binary, 0, 255, THRESH_BINARY|THRESH_OTSU);      //二值化 \t\t//imshow(&quot;Video-demo&quot;, binary);\t\tbitwise_not(frame, frame);         //bitwise_xor,bitwise_and\t\timshow(&quot;Video-demo&quot;, frame);\t\t//writer.write(frame);\t\tchar c = waitKey(100);\t\tif(c == 27)&#123;\t\t\tbreak;\t\t&#125;\t&#125;\t\twaitKey(0);\treturn 0;&#125;\n相关类和函数Capture 类//构造函数：filename – 打开的视频文件名。device – 打开的视频捕获设备id ，如果只有一个摄像头可以填0，表示打开默认的摄像头。 VideoCapture::VideoCapture();VideoCapture::VideoCapture(const string&amp; filename);VideoCapture::VideoCapture(int device);//open 打开一个视频文件或者打开一个捕获视频的设备bool VideoCapture::open(const string&amp; filename);bool VideoCapture::open(int device);//先实例化再初始化VideoCapture capture;capture.open(&quot;dog.avi&quot;);//在实例化的同时进行初始化VideoCapture(&quot;dog.avi&quot;);//isopenbool VideoCapture::isOpened();//release 关闭视频文件或者摄像头void VideoCapture::release();//grab 抓取下一个帧，假如调用成功返回truebool VideoCapture::grab();//retrieve 解码并且返回刚刚抓取的视频帧bool VideoCapture::retrieve(Mat&amp; image, int channel=0);//read 该函数结合VideoCapture::grab()和VideoCapture::retrieve()其中之一被调用，用于捕获、解码和返回下一个视频帧这是一个最方便的函数对于读取视频文件或者捕获数据从解码和返回刚刚捕获的帧VideoCapture&amp; VideoCapture::operator&gt;&gt;(Mat&amp; image);bool VideoCapture::read(Mat&amp; image);// 方法一 capture.read(frame); // 方法二 capture.grab(); // 方法三capture.retrieve(frame); // 方法四capture &gt;&gt; frame;//get 帧率、总帧数、尺寸、格式等，VideoCapture的get方法可以获取这些属性double VideoCapture::get(int propId);//参数是属性的ID//set 设置属性 (属性ID，要设置的值)bool VideoCapture::set(int propertyId, double value);\n#include &lt;iostream&gt; #include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt; int main(int argc,char* argv[])&#123;    cv::VideoCapture capture(argv[1]);    if(!capture.isOpened())     &#123;        std::cout&lt;&lt;&quot;video not open.&quot;&lt;&lt;std::endl;        return 1;    &#125;    //获取当前视频帧率    double rate = capture.get(CV_CAP_PROP_FPS);    //当前视频帧    cv::Mat frame;    //每一帧之间的延时    //与视频的帧率相对应    int delay = 1000/rate;    bool stop(false);    while(!stop)    &#123;        if(!capture.read(frame))        &#123;            std::cout&lt;&lt;&quot;no video frame&quot;&lt;&lt;std::endl;            break;         &#125;         //此处为添加对视频的每一帧的操作方法        int frame_num = capture.get(CV_CAP_PROP_POS_FRAMES);        std::cout&lt;&lt;&quot;Frame Num : &quot;&lt;&lt;frame_num&lt;&lt;std::endl;        if(frame_num==20)        &#123;            capture.set(CV_CAP_PROP_POS_FRAMES,10);        &#125;         cv::imshow(&quot;video&quot;,frame);        //引入延时        //也可通过按键停止        if(cv::waitKey(delay)&gt;0)        stop = true;    &#125;      //关闭视频，手动调用析构函数（非必须）    capture.release();    return 0;&#125;\nVideoWriter​ 类//三种构造函数VideoWriter::VideoWriter()VideoWriter::VideoWriter(const String &amp;filename, int fourcc, double fps, Size frameSize, bool isColor=true)VideoWriter::VideoWriter(const String &amp;filename, int apiPreference, int fourcc, double fps, Size frameSize, bool isColor=true)\nfilename​ : 输出视频文件的路径名称\nfourcc​ : 字符类型的编码，表示用于编码视频文件的编码器。其中\n\nVideoWriter::fourcc(&#39;P’,’I’,’M’,’1’) 表示 MPEG-1 编码文件扩展名为 .avi​ ; \nVideoWriter::fourcc(&#39;X&#39;,&#39;V&#39;,&#39;I&#39;,&#39;D&#39;) 表示 MPEG-4 编码文件扩展名为 .avi ; \nVideoWriter::fourcc(&#39;X&#39;,’2&#39;,&#39;6&#39;,&#39;4&#39;)​ 表示 MPEG-4​ 编码文件扩展名为 .mp4​ ;\nVideoWriter::fourcc(&#39;I&#39;,’4&#39;,&#39;2&#39;,&#39;0&#39;) 表示 YUV 编码，文件扩展名为.avi ;\nVideoWriter::fourcc(&#39;M&#39;,’P&#39;,&#39;4&#39;,&#39;V&#39;) 表示旧的 MPEG-4 编码，文件扩展名为 .avi ;\nVideoWriter::fourcc(&#39;T&#39;,’H&#39;,&#39;E&#39;,&#39;O&#39;) 表示使用 ogg vorbis ，文件扩展名为 .ogv ;\nVideoWriter::fourcc(&#39;F&#39;,&#39;L&#39;,&#39;V&#39;,&#39;1&#39;) 表示 flash video ,文件扩展名为 .flv ;\n\nfps​ : 表示帧率\nframeSize​ : 表示每一帧图像的大小\nisColor : 灰度图像或者是彩色图像（仅仅在 windows 上支持）\napiPreference ： 使用指定的 API，例如可以使用 cv::CAP_FFMPEG 或者 cv::CAP_GSTREAMER​ 等。\n//常用函数VideoWriter::isOpened()    VideoWriter::getBackednName()    VideoWriter::open(const String &amp;filename, int fourcc, double fps, Size frameSize, bool isColor=true);VideoWriter::open(const String &amp;filename,int apiPreference,int fourcc,double fps,Size frameSize,bool isColor=true);VideoWriter::release()    VideoWriter::get(int propId);VideoWriter::set(int propId,double value);\nSize 类template&lt;typename _Tp&gt; class Size_&#123;public:    typedef _Tp value_type;    //! various constructors    Size_();    Size_(_Tp _width, _Tp _height);    Size_(const Size_&amp; sz);    Size_(const CvSize&amp; sz);    Size_(const CvSize2D32f&amp; sz);    Size_(const Point_&lt;_Tp&gt;&amp; pt);    Size_&amp; operator = (const Size_&amp; sz);    //! the area (width*height)    _Tp area() const;    //! conversion of another data type.    template&lt;typename _Tp2&gt; operator Size_&lt;_Tp2&gt;() const;    //! conversion to the old-style OpenCV types    operator CvSize() const;    operator CvSize2D32f() const;    _Tp width, height; // the width and the height&#125;;\ncvtColor_CV_8U_ 图像 其通道值范围为0到255\n_CV_16U_ 时其值通道值范围为0到65535\n_CV_32F_ 时，其通道值范围为0到1\n//src：为原图片 code：需要进行色彩空间转换的结果void cv::cvtColor (InputArray src, OutputArray dst, int code, int dstCn = 0)\nthreshold去掉噪，例如过滤很小或很大像素值的图像点\ndouble threshold( InputArray src, OutputArray dst, double thresh, double maxval, int type )//src 源图像Mat对象//dst 目标图像Mat对象//thresh 设定的阈值//maxval 是当灰度值大于（或小于）阈值时将该灰度值赋成的值//type 二值化的方式\n二值化的方式, 常用的有如下5种\nCV_THRESH_BINARY      =0,  /**大于阈值的部分被置为255，小于部分被置为0 */CV_THRESH_BINARY_INV  =1,  /**大于阈值部分被置为0，小于部分被置为255    */CV_THRESH_TRUNC       =2,  /**大于阈值部分被置为threshold，小于部分保持原样   */CV_THRESH_TOZERO      =3,  /**小于阈值部分被置为0，大于部分保持不变*/CV_THRESH_TOZERO_INV  =4,  /**大于阈值部分被置为0，小于部分保持不变 */\n#include&lt;opencv2/opencv.hpp&gt;using namespace cv;int main() &#123;    Mat src = imread(&quot;C:/Users/Administrator/Desktop/txyzm.png&quot;);//引入源图像    if (src.empty()) &#123;        return -1;    &#125;    Mat graySrc,dst;    cvtColor(src, graySrc,CV_BGR2GRAY);//转换为灰度图像    threshold(graySrc, dst, 170, 255, CV_THRESH_BINARY);//图像二值化    imshow(&quot;dst&quot;, dst);//展示目标图像    waitKey(0);    return 0;&#125;\nbitwise//bitwise_not 将二指图片的效果反转既黑色变白色，白色变黑色bitwise_not(InputArray src, OutputArray dst, InputArray mask = noArray());//bitwise_xor 对两个图像进行”异“处理//bitwise_or 计算每个位操作分离的两个数组或一个数\nnamedWindowvoid nameWindow(const string&amp; winname,int flags = WINDOW_AUTOSIZE) ;\n\nWINDOW_AUTOSIZE 窗口大小自动适应图片大小，并且不可手动更改。（上面图1就是使用的它）\n\nWINDOW_NORMAL 用户可以改变这个窗口大小（上面图2就是使用的它）\n\nWINDOW_OPENGL 窗口创建的时候会支持OpenGL\n\n\nChapter 2 背景消去建模（BSM）：背景不常变化的图像分割 （GMM — 高斯混合模型）\n#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main()&#123;\tVideoCapture capture;\tcapture.open(&quot;...&quot;);\tif(!capture.isOpened())&#123;         //如果打开失败了\t\tcout &lt;&lt; &quot;could not load&quot; &lt;&lt; endl;\t\treturn -1; \t&#125;\t\tMat frame;\tMat bsmaskMOG2;\tnamedWindow(&quot;input video&quot;, CV_WINDOW_AUTOSIZE);\tnamedWindow(&quot;MOG2&quot;, CV_WINDOW_AUTOSIZE);\tPtr&lt;BackgroudSubtractor&gt; pMOG2 = createBackgroundSubtractorMOG2();  //选择API\twhile(capture.read(frame))&#123;\t\timshow(&quot;inpupt video&quot;, frame);\t\tpMOG2 -&gt; apply(frame, bsmaskMOG2);\t\timshow(&quot;MOG2&quot;, bsmaskMOG2);\t\tchar c = waitKey(100);\t\tif(c == 27)&#123;\t\t\tbreak;\t\t&#125;\t&#125;\t\tcapture.release();\twaitKey(0);\treturn 0;&#125;\n机器学习（_KNN_ — _K_​ 个最近邻）\n#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main()&#123;\tVideoCapture capture;\tcapture.open(&quot;...&quot;);\tif(!capture.isOpened())&#123;         //如果打开失败了\t\tcout &lt;&lt; &quot;could not load&quot; &lt;&lt; endl;\t\treturn -1; \t&#125;\t\tMat frame;\tMat bsmaskKNN;\tnamedWindow(&quot;input video&quot;, CV_WINDOW_AUTOSIZE);\tnamedWindow(&quot;KNN&quot;, CV_WINDOW_AUTOSIZE);\tPtr&lt;BackgroudSubtractor&gt; pKNN = createBackgroundSubtractorKNN();\twhile(capture.read(frame))&#123;\t\timshow(&quot;inpupt video&quot;, frame);\t\tpKNN -&gt; apply(frame, bsmaskKNN);\t\timshow(&quot;KNN&quot;, bsmaskKNN);\t\tchar c = waitKey(100);\t\tif(c == 27)&#123;\t\t\tbreak;\t\t&#125;\t&#125;\t\tcapture.release();\twaitKey(0);\treturn 0;&#125;\n开操作去噪声\n#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;int main()&#123;\tVideoCapture capture;\tcapture.open(&quot;...&quot;);\tif(!capture.isOpened())&#123;         //如果打开失败了\t\tcout &lt;&lt; &quot;could not load&quot; &lt;&lt; endl;\t\treturn -1; \t&#125;\t\tMat frame;\tMat bsmaskMOG2;\tnamedWindow(&quot;input video&quot;, CV_WINDOW_AUTOSIZE);\tnamedWindow(&quot;MOG2&quot;, CV_WINDOW_AUTOSIZE);\t\tMat kernel = getStructuringELement(MORPH_RECT, Size(3, 3), Point(-1, -1));\t\tPtr&lt;BackgroudSubtractor&gt; pMOG2 = createBackgroundSubtractorMOG2();  //选择API\twhile(capture.read(frame))&#123;\t\timshow(&quot;inpupt video&quot;, frame);\t\tpMOG2 -&gt; apply(frame, bsmaskMOG2);\t\tmorphologyEx(bsmaskMOG2, bsmaskMOG2, MORPH_OPEN, kernel, Point(-1, -1));\t\timshow(&quot;MOG2&quot;, bsmaskMOG2);\t\tchar c = waitKey(50);\t\tif(c == 27)&#123;\t\t\tbreak;\t\t&#125;\t&#125;\t\tcapture.release();\twaitKey(0);\treturn 0;&#125;\n相关类和函数BackgroundSubtractor\nBackgroundSubtractor （父类）   -  BackgroundSubtractorMOG2    -  BackgroundSubtractorKNN\nChapter 3 对象检测与跟踪：基于颜色inRange过滤利用颜色进行过滤\n形态学操作提取开操作 去噪声 膨胀 \n轮廓查找外接矩形获取位置标定#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace std;using namespace cv;Rect roi;void processFrame(Mat &amp;mask, Rect &amp;rect);int main()&#123;\tVideoCapture capture;\tcapture.open(&quot;...&quot;);\tif(!capture.isOpened())&#123;         //如果打开失败了\t\tcout &lt;&lt; &quot;could not load&quot; &lt;&lt; endl;\t\treturn -1; \t&#125;\t\tMat frame, mask;\tMat kernel1 = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1));\tMat kernel2 = getStructuringElement(MORPH_RECT, Size(5, 5), Point(-1, -1));\t\tnamedWindow(&quot;input video&quot;, CV_WINDOW_AUTOSIZE);\tnamedWindow(&quot;track mask&quot;, CV_WINDOW_AUTOSIZE);\twhile(capture.read(frame))&#123;\t\tinRange(frame, Scalar(0, 0, 127), Scalar(120, 255, 120), mask); //过滤 \t\tmorphologyEx(mask, mask, MORPH_OPEN, kernel1, Point(-1, -1), 1); //开操作\t\timshow(&quot;track mask&quot;, mask);\t\tdilate(mask, mask, kernel2, Point(-1, -1), 4); //膨胀\t\timshow(&quot;dilate mask&quot;, mask);\t\t\t\tprocessFrame(mask, roi); //找轮廓并标定\t\t\t\trectangle(frame, roi, Scalar(0, 0, 255), 3, 8, 0);\t\t\t\timshow(&quot;input video&quot;, frame);\t\tchar c = waitKey(50);\t\tif(c == 27)&#123;\t\t\tbreak;\t\t&#125;\t&#125;\t\tcapture.release();\twaitKey(0);\treturn 0;&#125;void processFrame(Mat &amp;mask, Rect &amp;rect)&#123; //查找轮廓 \tvector&lt;vector&lt;Point&gt; &gt; contours;\tvector&lt;Vec4i&gt; hireachy;\tfindContours(mask, contours, hireachy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point(0, 0));\tif(contours.size() &gt; 0)&#123;\t\tdouble maxArea = 0.0;\t\tfor(size_t t = 0; t &lt; contours.size(); ++t)&#123;\t\t\tdouble area = contourArea(contours[static_cast&lt;int&gt;(t)]);\t\t\tif(area &gt; maxArea)&#123;\t\t\t\tmaxArea = area;\t\t\t\trect = boundingRect(contours[static_cast&lt;int&gt;(t)]);\t\t\t&#125;\t\t&#125;\t&#125;else&#123;\t\trect.x = rect.y = rect.width = rect.height = 0;\t&#125;&#125;\n相关类和函数inRange()\n   OpenCV中的inRange()函数可实现二值化功能（这点类似threshold()函数），更关键的是可以同时针对多通道进行操作，使用起来非常方便！主要是将在两个阈值内的像素值设置为白色（255），而不在阈值区间内的像素值设置为黑色（0），该功能类似于之间所讲的双阈值化操作。\n  void inRange(InputArray src, InputArray lowerb, InputArray upperb, OutputArray dst);//src 输入要处理的图像，可以为单通道或多通道//lowerb 包含下边界的数组或标量//upperb 包含上边界数组或标量//dst 输出图像，与输入图像src 尺寸相同且为CV_8U 类型\nChecks if array elements lie between the elements of two other arrays.即检查数组元素是否在另外两个数组元素值之间。这里的数组通常也就是矩阵Mat或向量。\n\n该函数输出的dst是一幅二值化之后的图像。\n\nmorphologyEx\n形态学变化函数\n(4条消息) opencv 形态学变换 morphologyEx函数_keen_zuxwang的博客-CSDN博客\nfindContours\n检测物体轮廓\nfindContours(InputOutputArray image, OutputArrayOfArrays contours,  OutputArray hierarchy, int mode, int method, Point offset = Point());//image 单通道图像矩阵 灰度图or二值图像（Canny、拉普拉斯等边缘检测算子）//contours 向量vector&lt;vector&lt;Point&gt;&gt; contours//hierarchy 向量vector&lt;Vec4i&gt; hierarchy   vec4i:typedef Vec&lt;int, 4&gt; Vec4i; //mode 轮廓检索模式//method 定义轮廓的近似方法//Point偏移量 所有的轮廓信息相对于原始图像对应点的偏移量 相当于在每一个检测出的轮廓点上加上该偏移量 并且Point还可以是负值!\n轮廓检索模式\nCV_RETR_EXTERNAL //只检测最外围轮廓CV_RETR_LIST //检测所有的轮廓 轮廓不建立等级关系 即不存在父轮廓或内嵌轮廓CV_RETR_CCOMP //检测所有的轮廓 建立两个等级关系CV_RETR_TREE //检测所有轮廓 所有轮廓建立一个等级树结构\n定义轮廓的近似方法\nCV_CHAIN_APPROX_NONE //保存物体边界上所有连续的轮廓点到contours向量内CV_CHAIN_APPROX_SIMPLE //仅保存轮廓的拐点信息 把所有轮廓拐点处的点保存入contours  CV_CHAIN_APPROX_TC89_L1 //使用teh-Chinl chain 近似算法CV_CHAIN_APPROX_TC89_KCOS //使用teh-Chinl chain 近似算法\ncontourArea\n计算轮廓面积\ndouble contourArea(InputArray contour, bool oriented = false);//contour 输入的二维点集（轮廓顶点）可以是 vector 或 Mat 类型//riented，面向区域标识符 有默认值 false 若为 true 该函数返回一个带符号的面积值 正负取决于轮廓的方向（顺时针还是逆时针） 若为 false 表示以绝对值返回\narcLength\n计算封闭轮廓周长\ndouble arcLength(InputArray curve, bool closed);//contour 输入的二维点集（轮廓顶点）可以是 vector 或 Mat 类型//closed 用于指示曲线是否封闭\nboundingRect\n计算轮廓的垂直边界最小矩形，矩形是与图像上下边界平行的\nRect boundingRect(InputArray points);//points 输入的二维点集（轮廓顶点）可以是 vector 或 Mat 类型\n","categories":["HDU's Learning"],"tags":["OpenCV"]},{"title":"OpenCV (bilibili教程代码)","url":"/2021/07/26/OPENCV1-0-1/","content":"我是代码搬运机\n\ngithub.com\nChapter 1#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Images/// &lt;/summary&gt;//void main() &#123;//\tstring path = &quot;Resources/test.png&quot;;//\tMat img=imread(path);//matrix data type 由opencv引入来处理图像//\timshow(&quot;Image&quot;, img);//\twaitKey(0);//增加延时，0表示无穷//&#125;/// &lt;summary&gt;/// Video/// //视频是一系列图像，需要遍历所有图像或帧 一一捕获并显示，因此将使用while循环/// &lt;/summary&gt;//void main() &#123;//\tstring path = &quot;Resources/test_video.mp4&quot;;//\tVideoCapture cap(path);//\tMat img;////\twhile (true) &#123;//\t\tcap.read(img);//\t\timshow(&quot;Image&quot;, img);//\t\twaitKey(20);//增加延时 20ms//\t&#125;//\t//&#125;/// &lt;summary&gt;/// Webcam/// 与导入视频不同的是，不需要视频路径，只需要给相机ID，id=0表示默认的摄像头/// &lt;/summary&gt;//void main() &#123;//\tVideoCapture cap(0);//相机id=0//\tMat img;//\t//while (true) &#123;\t//\tcap.read(img);\t//\timshow(&quot;Image&quot;, img);\t//\twaitKey(1);//增加延时 1ms，以免太慢\t//&#125;////&#125;\nChapter 2#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Basic Function/// &lt;/summary&gt;//void main() &#123;//\tstring path = &quot;Resources/test.png&quot;;//\tMat img=imread(path);//matrix data type 由opencv引入来处理图像//\tMat imgGray,imgBlur,imgCanny,imgDil,imgErode;////\tcvtColor(img, imgGray, COLOR_BGR2GRAY);//cvt是convert的缩写，将图像从一种颜色空间转换为另一种颜色空间。//\tGaussianBlur(imgGray, imgBlur,Size(7,7),5,0);//使用高斯滤波器模糊图像。该函数将源图像与指定的高斯核进行卷积,Size(7,7)是核大小,数字越大越模糊//\tCanny(imgBlur, imgCanny, 25, 75);//边缘检测，阈值1，2可调，目的：显示更多的边缘//\t//\tMat kernel = getStructuringElement(MORPH_RECT, Size(3, 3));//创建一个核，增加Size（只能是奇数）会扩张/侵蚀更多//\tdilate(imgCanny, imgDil, kernel);//扩张边缘（增加边缘厚度）//\terode(imgDil, imgErode, kernel);//侵蚀边缘（减小边缘厚度）//\timshow(&quot;Image&quot;, img);//\timshow(&quot;Image Gray&quot;, imgGray);//\timshow(&quot;Image Blur&quot;, imgBlur);//\timshow(&quot;Image Canny&quot;, imgCanny);//\timshow(&quot;Image Dilation&quot;, imgDil);//\timshow(&quot;Image Erode&quot;, imgErode);//\twaitKey(0);//增加延时，0表示无穷//&#125;\nChapter 3//学习如何调整大小以及裁剪图像#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Resize and Crop/// &lt;/summary&gt;//void main() &#123;//\tstring path = &quot;Resources/test.png&quot;;//\tMat img=imread(path);//matrix data type 由opencv引入来处理图像//\tMat imgResize,imgCrop;//\tcout &lt;&lt; img.size() &lt;&lt; endl;//打印图像尺寸//\t//resize(img, imgResize, Size(640, 480));//指定图片尺寸缩放//\tresize(img, imgResize, Size(),0.5,0.5);//指定缩放比例，不指定图片尺寸////\t//矩形数据类型//\tRect roi(200, 100, 300, 300);//以左上角为坐标原点，（200，100）为矩形的左上角坐标，300,300为矩形长宽//\timgCrop = img(roi);//裁剪图像，为了找到特定区域 添加更多处理 roi:region of interest//\timshow(&quot;Image&quot;, img);//\timshow(&quot;Image Resize&quot;, imgResize);//\timshow(&quot;Image Crop&quot;, imgCrop);//\t//\twaitKey(0);//增加延时，0表示无穷//&#125;\nChapter 4//学习如何绘制形状（圆形、矩形、线段）和如何在图片上写字#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Draw Shapes and Text/// &lt;/summary&gt;//void main() &#123;//\t//创建空白图像//\t//Scalar(255, 0, 255)，（蓝色：255，0，0），（紫色：255，0，255），（黑色：0，0，0），（白色：255，255，255）//\tMat img(512, 512, CV_8UC3, Scalar(255, 255, 255));//(512,512)为图片大小，CV8UC3中8表示每个像素的值从0到255，3表示3个颜色通道BGR,Scalar(255, 0, 0)表示图像将具有的颜色//\t//\tcircle(img, Point(256, 256), 155,Scalar(0,69,255),FILLED);//第一个参数：图片，第二个参数是圆心坐标，第三个参数是圆大小，第四个参数是颜色，第五个参数是厚度（可以不写），想要填充可以填FILLED//\trectangle(img, Point(130,226), Point(382,286),Scalar(255,255,255),FILLED);//第一个Point给矩形左上角坐标，第二个Point给矩形右下角坐标//\tline(img, Point(130, 296), Point(382, 296), Scalar(255, 255, 255), 2);//第一个Point是起点坐标、第二个Point是终点坐标//\tputText(img, &quot;zhuhuijin&quot;, Point(137, 262), FONT_HERSHEY_DUPLEX, 0.75, Scalar(0, 69, 255), 2);//\t//\timshow(&quot;Image&quot;, img);//\twaitKey(0);//增加延时，0表示无穷//&#125;\nChapter 5//学习如何扭曲图像，来扫描文档#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Warp Images/// &lt;/summary&gt;//float w = 250, h = 350;//图片大小//Mat matrix, imgWarp;//void main() &#123;//\t//图片用画图打开，在屏幕左下角会显示点的坐标//\tstring path = &quot;Resources/cards.jpg&quot;;//\tMat img=imread(path);//matrix data type 由opencv引入来处理图像//\tPoint2f src[4] = &#123; &#123;529,142&#125;,&#123;771,190&#125;,&#123;405,395&#125;,&#123;674,457&#125; &#125;;//Point2f表示浮点数//\tPoint2f dst[4] = &#123; &#123;0.0f,0.0f&#125;,&#123;w,0.0f&#125;,&#123;0.0f,h&#125;,&#123;w,h&#125; &#125;;//Point2f表示浮点数////\tmatrix = getPerspectiveTransform(src, dst);//\twarpPerspective(img, imgWarp, matrix, Point(w,h));//\t//\t//确定src坐标是否正确//\tfor (int i = 0; i &lt; 4; i++) &#123;//\t\tcircle(img, src[i], 10, Scalar(0, 0, 255), FILLED);//\t&#125;////\timshow(&quot;Image&quot;, img);//\timshow(&quot;Image Warp&quot;, imgWarp);//\twaitKey(0);//增加延时，0表示无穷//&#125;\nChapter 6//学习检测图片中的颜色，来创建特定对象的对象检测器#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Color Detection/// &lt;/summary&gt;//int hmin = 0, smin = 0, vmin = 0;//int hmax = 179, smax = 255, vmax = 255;//如何确定这6个值，每次都更改所有这些再次运行很痛苦 --&gt;创建跟踪栏（使我们可以实时更改这些值）//void main() &#123;//\tstring path = &quot;Resources/shapes.png&quot;;//\tMat img=imread(path);//\tMat imgHSV,mask;//\tcvtColor(img, imgHSV, COLOR_BGR2HSV);//转换图像到HSV空间，在其中查找颜色更加容易//\tnamedWindow(&quot;Trackbars&quot;, (640, 200));//(640,200)是尺寸//\t//运行时，把3个min的都移到最小值，把3个max的都移到最大值，然后移动使其保持为白色//\tcreateTrackbar(&quot;Hue Min&quot;, &quot;Trackbars&quot;, &amp;hmin, 179);//对于hue色相饱和度最大180,对于另外两个色相饱和度最大255//\tcreateTrackbar(&quot;Hue Max&quot;, &quot;Trackbars&quot;, &amp;hmax, 179);//\tcreateTrackbar(&quot;Sat Min&quot;, &quot;Trackbars&quot;, &amp;smin, 255);//\tcreateTrackbar(&quot;Sat Max&quot;, &quot;Trackbars&quot;, &amp;smax, 255);//\tcreateTrackbar(&quot;Val Min&quot;, &quot;Trackbars&quot;, &amp;vmin, 255);//\tcreateTrackbar(&quot;Val Max&quot;, &quot;Trackbars&quot;, &amp;vmax, 255);//\t//\twhile (true) &#123;//\t\t//检查数组元素是否位于其他两个数组的元素之间。//\t\t//imgHSV为输入图像，mask为输出图像////\t\tScalar lower(hmin, smin, vmin);//\t\tScalar upper(hmax, smax, vmax);//\t\tinRange(imgHSV, lower, upper, mask);//定义颜色下限和上限，因为由于照明和不同的阴影，颜色的值将不完全相同，会是一个值的范围//\t\timshow(&quot;Image&quot;, img);//\t\timshow(&quot;Image HSV&quot;, imgHSV);//\t\timshow(&quot;Image mask&quot;, mask);//\t\twaitKey(1);//增加延时//\t&#125;//&#125;\nChapter 7//学习如何检测形状或图像中的轮廓#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Shapes/// &lt;/summary&gt;//! 获取轮廓void getContours(Mat imgDil,Mat img) &#123;//imgDil是传入的扩张边缘的图像用来查找轮廓，img是要在其上绘制轮廓的图像\tvector&lt;vector&lt;Point&gt;&gt; contours;//轮廓检测到的轮廓。每个轮廓线存储为一个点的向量\t\tvector&lt;Vec4i&gt; hierarchy;//包含关于映像拓扑的信息  typedef Vec&lt;int, 4&gt; Vec4i;具有4个整数值\t\t//在二值图像中查找轮廓。该函数利用该算法从二值图像中提取轮廓\tfindContours(imgDil, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);\t//drawContours(img, contours, -1, Scalar(255, 0, 255), 2);//img：要绘制轮廓在什么图片上，contours：要绘制的轮廓，-1定义要绘制的轮廓号（-1表示所有轮廓），Saclar表示轮廓颜色，2表示厚度\tvector&lt;vector&lt;Point&gt;&gt; conPoly(contours.size());//conploy的数量应小于contours\tvector&lt;Rect&gt; boundRect(contours.size());\t//过滤器：通过轮廓面积来过滤噪声\tfor (int i = 0; i &lt; contours.size(); i++) &#123;//遍历检测到的轮廓\t\tint area = contourArea(contours[i]);\t\t\t\t//cout &lt;&lt; area &lt;&lt; endl;\t\t\t\tstring objectType;\t\tif (area &gt; 1000) &#123;//轮廓面积＞1000才绘制\t\t\t//计算轮廓周长或凹坑长度。该函数计算了曲线长度和封闭的周长。\t\t\tfloat peri = arcLength(contours[i], true);//计算封闭轮廓周长\t\t\tapproxPolyDP(contours[i], conPoly[i],0.02*peri,true);//以指定的精度近似多边形曲线。第二个参数conPloy[i]存储近似的结果，是输出。\t\t\t\t\t\t\t\t\tboundRect[i]=boundingRect(conPoly[i]);//计算边界矩形\t\t\t\t\t\tint objCor = (int)conPoly[i].size();//找近似多边形的角点,三角形有3个角点，矩形/正方形有4个角点，圆形&gt;4个角点\t\t\tcout &lt;&lt; objCor &lt;&lt; endl;\t\t\tif (objCor == 3) &#123;objectType = &quot;Tri&quot;;&#125;\t\t\telse if (objCor == 4) &#123;\t\t\t\tfloat aspRatio = (float)boundRect[i].width / (float)boundRect[i].height;//宽高比\t\t\t\tif (aspRatio &gt; 0.95 &amp;&amp; aspRatio &lt; 1.05) &#123; objectType = &quot;Square&quot;;&#125;//矩形的宽高比不会正好等于1\t\t\t\telse objectType = &quot;Rect&quot;;\t\t\t&#125;\t\t\telse if (objCor &gt; 4) &#123; objectType = &quot;Circle&quot;;&#125;\t\t\t\t\t\tdrawContours(img, conPoly, i, Scalar(255, 0, 255), 2);\t\t\trectangle/*绘制边界矩形*/(img, boundRect[i].tl()/*tl()：topleft矩形左上角坐标*/, boundRect[i].br()/*br()：bottom right矩形右下角坐标*/, Scalar(0, 255, 0), 5);\t\t\tputText(img, objectType, &#123;boundRect[i].x,boundRect[i].y-5&#125;/*文字坐标*/, FONT_HERSHEY_PLAIN, 1, Scalar(0, 69, 255), 2);\t\t&#125;\t&#125;&#125;//void main() &#123;//\tstring path = &quot;Resources/shapes.png&quot;;//\tMat img=imread(path);//\t//\t//在检测形状前，对图片预处理：转换为灰度、添加高斯模糊、使用Canny边缘检测器、扩张边缘//\tMat imgGray, imgBlur, imgCanny, imgDil, imgErode;//\tcvtColor(img, imgGray, COLOR_BGR2GRAY);//cvt是convert的缩写，将图像从一种颜色空间转换为另一种颜色空间。//\tGaussianBlur(imgGray, imgBlur,Size(3,3),3,0);//使用高斯滤波器模糊图像。该函数将源图像与指定的高斯核进行卷积,Size(7,7)是核大小,数字越大越模糊//\tCanny(imgBlur, imgCanny, 25, 75);//边缘检测，阈值1，2可调，目的：显示更多的边缘//\tMat kernel = getStructuringElement(MORPH_RECT, Size(3, 3));//创建一个核，增加Size（只能是奇数）会扩张/侵蚀更多//\tdilate(imgCanny, imgDil, kernel);//扩张边缘（增加边缘厚度）//\t//\tgetContours(imgDil,img);//img是在其上绘轮廓的图片////\timshow(&quot;Image&quot;, img);//\t/*imshow(&quot;Image Gray&quot;, imgGray);//\timshow(&quot;Image Blur&quot;, imgBlur);//\timshow(&quot;Image Canny&quot;, imgCanny);//\timshow(&quot;Image Dil&quot;, imgDil);*///\twaitKey(0);//增加延时，0表示无穷//&#125;\nChapter 8//学习检测图像中的面部#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;opencv2/objdetect.hpp&gt;//对象检测头文件#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Images/// &lt;/summary&gt;//void main() &#123;//\tstring path = &quot;Resources/test.png&quot;;//\tMat img=imread(path);//\tCascadeClassifier faceCascade;/*用于对象检测的级联分类器类*///\tfaceCascade.load(&quot;Resources/haarcascade_frontalface_default.xml&quot;);//从文件加载分类器(已经训练好的模型)////\tif (faceCascade.empty()) &#123; cout &lt;&lt; &quot;XML file not loaded&quot; &lt;&lt; endl; &#125;//检测文件是否加载成功////\tvector&lt;Rect&gt; faces;//\tfaceCascade.detectMultiScale(img/*输入*/, faces/*输出*/, 1.1/*比例因子*/, 10/*最小邻居*/);//在输入图像中检测不同大小的对象。检测到的对象将以矩形列表的形式返回。//\t//\tfor (int i = 0; i &lt; faces.size(); i++) &#123;//\t\trectangle(img, faces[i].tl(),faces[i].br(), Scalar(255, 0, 255), 3);//绘制矩形//\t&#125;////\timshow(&quot;Image&quot;, img);//\twaitKey(0);//增加延时，0表示无穷//&#125;\nProject 1#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Project 1/// 使用HSV空间检测颜色、找到轮廓所在位置、取轮廓的位置然后创建一个圆/// &lt;/summary&gt;//Mat img;//vector&lt;vector&lt;int&gt;&gt; newPoints;////vector&lt;vector&lt;int&gt;&gt; myColors&#123; &#123;98,109,54,127,255,255&#125;,//蓝色（hmin smin vmin hmax smax vmax）//\t\t\t\t\t\t\t\t&#123;35,0,0,77,245,255&#125; &#125;;//绿色（hmin smin vmin hmax smax vmax）////vector&lt;Scalar&gt; myColorValues&#123; &#123;255,0,255&#125;,//蓝色//\t\t\t\t\t\t\t\t&#123;0,255,0&#125; &#125;;//绿色//////! 获取轮廓//Point getContours(Mat imgDil) &#123;//imgDil是传入的扩张边缘的图像用来查找轮廓，img是要在其上绘制轮廓的图像//\tvector&lt;vector&lt;Point&gt;&gt; contours;//轮廓检测到的轮廓。每个轮廓线存储为一个点的向量////\tvector&lt;Vec4i&gt; hierarchy;//包含关于映像拓扑的信息  typedef Vec&lt;int, 4&gt; Vec4i;具有4个整数值////\t//在二值图像中查找轮廓。该函数利用该算法从二值图像中提取轮廓//\tfindContours(imgDil, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);//\t//drawContours(img, contours, -1, Scalar(255, 0, 255), 2);//img：要绘制轮廓在什么图片上，contours：要绘制的轮廓，-1定义要绘制的轮廓号（-1表示所有轮廓），Saclar表示轮廓颜色，2表示厚度//\t//\tvector&lt;vector&lt;Point&gt;&gt; conPoly(contours.size());//conploy的数量应小于contours//\tvector&lt;Rect&gt; boundRect(contours.size());////\tPoint myPoint(0, 0);////\t//过滤器：通过轮廓面积来过滤噪声//\tfor (int i = 0; i &lt; contours.size(); i++) &#123;//遍历检测到的轮廓//\t\tint area = contourArea(contours[i]);//\t\t//\t\t//cout &lt;&lt; area &lt;&lt; endl;////\t\tstring objectType;//\t\tif (area &gt; 1000) &#123;//轮廓面积＞1000才绘制//\t\t\t//计算轮廓周长或凹坑长度。该函数计算了曲线长度和封闭的周长。//\t\t\tfloat peri = arcLength(contours[i], true);//计算封闭轮廓周长//\t\t\tapproxPolyDP(contours[i], conPoly[i], 0.02 * peri, true);//以指定的精度近似多边形曲线。第二个参数conPloy[i]存储近似的结果，是输出。////\t\t\tboundRect[i] = boundingRect(conPoly[i]);//计算边界矩形////\t\t\tmyPoint.x = boundRect[i].x + boundRect[i].width / 2;//\t\t\tmyPoint.y = boundRect[i].y;////\t\t\trectangle/*绘制边界矩形*/(img, boundRect[i].tl()/*tl()：topleft矩形左上角坐标*/, boundRect[i].br()/*br()：bottom right矩形右下角坐标*/, Scalar(0, 255, 0), 5);//\t\t\tdrawContours(img, conPoly, i, Scalar(255, 0, 255), 2);//\t\t\t//\t\t&#125;//\t&#125;//\treturn myPoint;//&#125;//////vector&lt;vector&lt;int&gt;&gt; findColor(Mat img) &#123;//\tMat imgHSV;//\tcvtColor(img, imgHSV, COLOR_BGR2HSV);//转换图像到HSV空间，在其中查找颜色更加容易////\tfor (int i = 0; i &lt; myColors.size(); i++)//\t&#123;//\t\tScalar lower(myColors[i][0], myColors[i][1], myColors[i][2]);//\t\tScalar upper(myColors[i][3], myColors[i][4], myColors[i][5]);//\t\tMat mask;//\t\tinRange(imgHSV, lower, upper, mask);//定义颜色下限和上限，因为由于照明和不同的阴影，颜色的值将不完全相同，会是一个值的范围//\t\t//imshow(to_string(i), mask);//\t\tPoint myPoint=getContours(mask);//\t\tif (myPoint.x != 0 &amp;&amp; myPoint.y != 0) &#123;//没检测到东西的时候就不加入新点//\t\t\tnewPoints.push_back(&#123; myPoint.x,myPoint.y,i &#125;);//i为颜色索引//\t\t&#125;//\t&#125;//\treturn newPoints;//\t//&#125;////void drawOnCanvas(vector&lt;vector&lt;int&gt;&gt; newPoints, vector&lt;Scalar&gt; myColorValues) &#123;//\tfor (int i = 0; i &lt; newPoints.size(); i++) &#123;//\t\tcircle(img, Point(newPoints[i][0], newPoints[i][1]),6,myColorValues[newPoints[i][2]],FILLED);//\t&#125;//&#125;////void main() &#123;//\tVideoCapture cap(0);//相机id=0//\t////\twhile (true) &#123;//\t\tcap.read(img);////\t\tnewPoints=findColor(img);//\t\tdrawOnCanvas(newPoints,myColorValues);//\t\timshow(&quot;Image&quot;, img);//\t\twaitKey(1);//增加延时 1ms，以免太慢//\t&#125;////&#125;\nProject 2#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Project 2 – Document Scanner/// 图像预处理：转换为灰度、添加模糊、使用Canny边缘检测器找到边缘（知道纸张在哪里）、基于纸张的坐标提取四个角得到顶视图/// &lt;/summary&gt;//Mat imgOriginal, imgGray, imgBlur, imgCanny, imgDil, imgErode, imgThre, imgWarp, imgCrop;//vector&lt;Point&gt; initialPoints,docPoints;//float w = 420, h = 596;//Mat preProcessing(Mat img) &#123;//\tcvtColor(img, imgGray, COLOR_BGR2GRAY);//cvt是convert的缩写，将图像从一种颜色空间转换为另一种颜色空间。//\tGaussianBlur(imgGray, imgBlur,Size(7,7),5,0);//使用高斯滤波器模糊图像。该函数将源图像与指定的高斯核进行卷积,Size(7,7)是核大小,数字越大越模糊//\tCanny(imgBlur, imgCanny, 25, 75);//边缘检测，阈值1，2可调，目的：显示更多的边缘//\t//\tMat kernel = getStructuringElement(MORPH_RECT, Size(3, 3));//创建一个核，增加Size（只能是奇数）会扩张/侵蚀更多//\tdilate(imgCanny, imgDil, kernel);//扩张边缘（增加边缘厚度）//\t//erode(imgDil, imgErode, kernel);//侵蚀边缘（减小边缘厚度）//\treturn imgDil;//&#125;////vector&lt;Point&gt;/*返回纸张的4个角点*/ getContours(Mat imgDil) &#123;//imgDil是传入的扩张边缘的图像用来查找轮廓，img是要在其上绘制轮廓的图像//\tvector&lt;vector&lt;Point&gt;&gt; contours;//轮廓检测到的轮廓。每个轮廓线存储为一个点的向量////\tvector&lt;Vec4i&gt; hierarchy;//包含关于映像拓扑的信息  typedef Vec&lt;int, 4&gt; Vec4i;具有4个整数值////\t//在二值图像中查找轮廓。该函数利用该算法从二值图像中提取轮廓//\tfindContours(imgDil, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);//\t//drawContours(img, contours, -1, Scalar(255, 0, 255), 2);//img：要绘制轮廓在什么图片上，contours：要绘制的轮廓，-1定义要绘制的轮廓号（-1表示所有轮廓），Saclar表示轮廓颜色，2表示厚度//\t//\tvector&lt;vector&lt;Point&gt;&gt; conPoly(contours.size());//conploy的数量应小于contours//\tvector&lt;Rect&gt; boundRect(contours.size());////\tvector&lt;Point&gt; biggest;//\tint maxArea = 0;////\t//过滤器：通过轮廓面积来过滤噪声//\tfor (int i = 0; i &lt; contours.size(); i++) &#123;//遍历检测到的轮廓//\t\tint area = contourArea(contours[i]);//\t\t//\t\t//cout &lt;&lt; area &lt;&lt; endl;////\t\tstring objectType;//\t\tif (area &gt; 1000) &#123;//轮廓面积＞1000才绘制//\t\t\t//计算轮廓周长或凹坑长度。该函数计算了曲线长度和封闭的周长。//\t\t\tfloat peri = arcLength(contours[i], true);//计算封闭轮廓周长//\t\t\tapproxPolyDP(contours[i], conPoly[i], 0.02 * peri, true);//以指定的精度近似多边形曲线。第二个参数conPloy[i]存储近似的结果，是输出。//\t\t\t//\t\t\tif (area &gt; maxArea&amp;&amp;conPoly[i].size()==4) &#123;//\t\t\t\tbiggest = &#123; conPoly[i][0],conPoly[i][1],conPoly[i][2],conPoly[i][3] &#125;;//\t\t\t\tmaxArea = area;//\t\t\t&#125;////\t\t\t//rectangle/*绘制边界矩形*/(imgOriginal, boundRect[i].tl()/*tl()：topleft矩形左上角坐标*/, boundRect[i].br()/*br()：bottom right矩形右下角坐标*/, Scalar(0, 255, 0), 5);//\t\t\t//drawContours(imgOriginal, conPoly, i, Scalar(255, 0, 255), 2);//\t\t\t//\t\t&#125;//\t&#125;//\treturn biggest;//&#125;////void drawPoints(vector&lt;Point&gt; points, Scalar color) &#123;//\tfor (int i = 0; i &lt; points.size(); i++) &#123;//\t\tcircle(imgOriginal, points[i], 10, color, FILLED);//\t\tputText(imgOriginal, to_string(i), points[i], FONT_HERSHEY_PLAIN, 4, color, 4);//\t&#125;//&#125;////vector&lt;Point&gt; reorder(vector&lt;Point&gt; points) &#123;//标记点的顺序会变，要确定一个顺序 0 1//\t\t\t\t\t\t\t\t\t\t\t//\t\t\t\t\t\t\t\t 2 3//\tvector&lt;Point&gt; newPoints;//\tvector&lt;int&gt;  sumPoints, subPoints;//\tfor (int i = 0; i &lt; 4; i++) &#123;//\t\tsumPoints.push_back(points[i].x + points[i].y);//\t\tsubPoints.push_back(points[i].x - points[i].y);//\t&#125;//\t//\tnewPoints.push_back(points[min_element/* find smallest element*/(sumPoints.begin(), sumPoints.end())-sumPoints.begin()]);//\tnewPoints.push_back(points[max_element/* find largest element*/(subPoints.begin(), subPoints.end()) - subPoints.begin()]);//\tnewPoints.push_back(points[min_element/* find smallest element*/(subPoints.begin(), subPoints.end()) - subPoints.begin()]);//\tnewPoints.push_back(points[max_element/* find largest element*/(sumPoints.begin(), sumPoints.end()) - sumPoints.begin()]);////\treturn newPoints;//&#125;////Mat getWarp(Mat img,vector&lt;Point&gt; points,float w,float h) &#123;//\tPoint2f src[4] = &#123; points[0],points[1],points[2],points[3] &#125;;//Point2f表示浮点数//\tPoint2f dst[4] = &#123; &#123;0.0f,0.0f&#125;,&#123;w,0.0f&#125;,&#123;0.0f,h&#125;,&#123;w,h&#125; &#125;;//Point2f表示浮点数////\tMat matrix = getPerspectiveTransform(src, dst);//\twarpPerspective(img, imgWarp, matrix, Point(w,h));////\treturn imgWarp;//&#125;////void main() &#123;//\tstring path = &quot;Resources/paper.jpg&quot;;//\timgOriginal=imread(path);////\t//resize(imgOriginal/*source*/, imgOriginal/*destination*/, Size()/*不定义尺寸*/, 0.5/*定义比例*/, 0.5/*定义比例*/);////\t//预处理//\timgThre = preProcessing(imgOriginal);//\t//获得轮廓--获得最大矩形//\tinitialPoints=getContours(imgThre);//\t//drawPoints(initialPoints, Scalar(0, 0, 255));//\tdocPoints = reorder(initialPoints);//\t//drawPoints(docPoints, Scalar(0, 255, 0));//\t//扭曲//\timgWarp = getWarp(imgOriginal, docPoints, w, h);//\t//裁剪多余的边--通过创建一个矩形//\tint cropValue = 5;//\tRect roi(cropValue/*每条边要减去的像素*/, cropValue, w - 2 * cropValue/*宽度*/, h - 2 * cropValue/*高度*/);//\timgCrop = imgWarp(roi);//\timshow(&quot;Image&quot;, imgOriginal);//\timshow(&quot;Image Dilation&quot;, imgThre);//\timshow(&quot;Image Warp&quot;, imgWarp);//\timshow(&quot;Image Crop&quot;, imgCrop);//\twaitKey(0);//&#125;\nProject 3//学习如何检测车牌和如何裁剪并保存这些区域#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;opencv2/objdetect.hpp&gt;//对象检测头文件#include&lt;iostream&gt;using namespace std;using namespace cv;/// &lt;summary&gt;/// Project 3 – License Plate(车牌) Detector/// &lt;/summary&gt;void main() &#123;\t\tVideoCapture cap(0);//相机id=0\tMat img;\t//加载模型\tCascadeClassifier plateCascade;/*用于对象检测的级联分类器类*/\tplateCascade.load(&quot;Resources/haarcascade_russian_plate_number.xml&quot;);//从文件加载分类器(已经训练好的模型)\tif (plateCascade.empty()) &#123; cout &lt;&lt; &quot;XML file not loaded&quot; &lt;&lt; endl; &#125;//检测文件是否加载成功\tvector&lt;Rect&gt; plates;\twhile (true) &#123;\t\tcap.read(img);\t\t//可以更改比例因子和最小邻居来调整检测成功率\t\tplateCascade.detectMultiScale(img/*输入*/, plates/*输出*/, 1.1/*比例因子*/, 10/*最小邻居*/);//在输入图像中检测不同大小的对象。检测到的对象将以矩形列表的形式返回。\t\t\t\t\t\tfor (int i = 0; i &lt; plates.size(); i++) &#123;\t\t\tMat imgCrop = img(plates[i]);//plates是矩形列表，plates[i]是矩形\t\t\t//imshow(to_string(i), imgCrop);\t\t\timwrite(&quot;Resources/Plates/&quot; + to_string(i) + &quot;.png&quot;, imgCrop);\t\t\trectangle(img, plates[i].tl(), plates[i].br(), Scalar(255, 0, 255), 3);//绘制矩形\t\t&#125;\t\timshow(&quot;Image&quot;, img);\t\twaitKey(1);//增加延时，0表示无穷\t&#125;&#125;\nColorpicker#include&lt;opencv2/imgcodecs.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;iostream&gt;using namespace std;using namespace cv;//int hmin = 0, smin = 0, vmin = 0;//int hmax = 179, smax = 255, vmax = 255;//如何确定这6个值，每次都更改所有这些再次运行很痛苦 --&gt;创建跟踪栏（使我们可以实时更改这些值）//Mat img;//Mat imgHSV, mask, imgColor;//void main() &#123;//\tVideoCapture cap(0);//相机id=0//\t//\t//\tnamedWindow(&quot;Trackbars&quot;, (640, 200));//创建窗口，(640,200)是尺寸//\t//运行时，把3个min的都移到最小值，把3个max的都移到最大值，然后移动使其保持为白色//\tcreateTrackbar(&quot;Hue Min&quot;, &quot;Trackbars&quot;, &amp;hmin, 179);//对于hue色相饱和度最大180,对于另外两个色相饱和度最大255//\tcreateTrackbar(&quot;Hue Max&quot;, &quot;Trackbars&quot;, &amp;hmax, 179);//\tcreateTrackbar(&quot;Sat Min&quot;, &quot;Trackbars&quot;, &amp;smin, 255);//\tcreateTrackbar(&quot;Sat Max&quot;, &quot;Trackbars&quot;, &amp;smax, 255);//\tcreateTrackbar(&quot;Val Min&quot;, &quot;Trackbars&quot;, &amp;vmin, 255);//\tcreateTrackbar(&quot;Val Max&quot;, &quot;Trackbars&quot;, &amp;vmax, 255);//\t//\twhile (true) &#123;//\t\t//检查数组元素是否位于其他两个数组的元素之间。//\t\t//imgHSV为输入图像，mask为输出图像//\t\tcap.read(img);//\t\tcvtColor(img, imgHSV, COLOR_BGR2HSV);//转换图像到HSV空间，在其中查找颜色更加容易//\t\tScalar lower(hmin, smin, vmin);//\t\tScalar upper(hmax, smax, vmax);//\t\tinRange(imgHSV, lower, upper, mask);//定义颜色下限和上限，因为由于照明和不同的阴影，颜色的值将不完全相同，会是一个值的范围//\t\tcout &lt;&lt; hmin &lt;&lt; &quot;,&quot; &lt;&lt; smin &lt;&lt; &quot;,&quot; &lt;&lt; vmin &lt;&lt; &quot;,&quot; &lt;&lt; hmax &lt;&lt; &quot;,&quot; &lt;&lt; smax &lt;&lt; &quot;,&quot; &lt;&lt; vmax &lt;&lt; endl;//\t\timshow(&quot;Image&quot;, img);//\t\timshow(&quot;Image HSV&quot;, imgHSV);//\t\timshow(&quot;Image mask&quot;, mask);//\t\twaitKey(1);//增加延时//\t&#125;//&#125;\n","categories":["HDU's Learning"],"tags":["OpenCV"]}]